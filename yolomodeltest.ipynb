{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import xml.etree.ElementTree as ET\n",
    "from ultralytics import YOLO\n",
    "import random\n",
    "import cv2\n",
    "import pytesseract\n",
    "import torch\n",
    "import easyocr\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import defaultdict, deque\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from requests_toolbelt.multipart.encoder import MultipartEncoder\n",
    "\n",
    "def get_def_headers():\n",
    "    return {\n",
    "        \"X-API-KEY\": \"123456\"\n",
    "    }\n",
    "\n",
    "def get_base_api():\n",
    "    return 'http://ec2-54-87-52-160.compute-1.amazonaws.com'\n",
    "\n",
    "\n",
    "# Camera id use for identify location of their cameras\n",
    "# please use these id below for testing:\n",
    "# ad7de137-9287-402a-8b70-53684d96c88f: Future park, Rangsit, Thanyaburi, Prachatipat, Pathum Thani\n",
    "# 2ec15a48-c819-494c-a807-5c0f41ebaf36: BTS Asok, Klongtoey Noei, Wattana, Bangkok\n",
    "# 0e76998d-0590-4679-924a-049f92ab0b81: Lotus Laksi, Bangkhen, Anusawaree, Bangkok\n",
    "\n",
    "\n",
    "# Send Notify API\n",
    "def send_notify(license_plate: str, camera_id: str, upload_id: str):\n",
    "    notify_api = get_base_api() + \"/notify/v1/send\"\n",
    "    notify_json = {\n",
    "        'licensePlate': license_plate,\n",
    "        'cameraId': camera_id,\n",
    "        'uploadId': upload_id\n",
    "    }\n",
    "    response = requests.post(notify_api, json=notify_json, headers=get_def_headers())\n",
    "    return response.json()\n",
    "\n",
    "# Upload Image API\n",
    "def upload_image(image_path):\n",
    "    upload_api = get_base_api() + \"/media/v1/upload/image\"\n",
    "    filename = os.path.basename(image_path)\n",
    "\n",
    "    with open(image_path, 'rb') as img_file:\n",
    "        multipart_data = MultipartEncoder(\n",
    "            fields={'image': (filename, img_file, 'image/jpeg')}\n",
    "        )\n",
    "        headers = get_def_headers()\n",
    "        headers['Content-Type'] = multipart_data.content_type\n",
    "        \n",
    "        response = requests.post(upload_api, data=multipart_data, headers=headers)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Send Notify without Image response: {'notifyId': 'c2a1390c-45e3-414b-a6fb-a530a0409b6d', 'status': 'PENDING'}\n"
     ]
    }
   ],
   "source": [
    "# Example Send Notify without Image\n",
    "no_img_license_plate = \"7กญ 3603 กรุงเทพมหานคร\"\n",
    "no_img_camera = \"ad7de137-9287-402a-8b70-53684d96c88f\"\n",
    "response = send_notify(no_img_license_plate, no_img_camera, '')\n",
    "print(\"Send Notify without Image response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Send Upload response: {'uploadId': '71bfe9c0-204f-4011-a1ed-6e81be8f386f', 'fileId': '5ff3a40a-513d-47c2-9d60-d0afacbf0e6f', 'filePath': '71bfe9c0-204f-4011-a1ed-6e81be8f386f/5ff3a40a-513d-47c2-9d60-d0afacbf0e6f.jpg', 'contentType': 'jpg', 'status': 'SUCCESS'}\n",
      "Send Notify with Image response: {'notifyId': 'c2a1390c-45e3-414b-a6fb-a530a0409b6d', 'status': 'PENDING'}\n"
     ]
    }
   ],
   "source": [
    "# Example Send Upload Image\n",
    "img_path = './runs/detect/predict4/car02.jpg'\n",
    "upload_response = upload_image(img_path)\n",
    "print(\"Send Upload response:\", upload_response)\n",
    "\n",
    "# Example Send Notify with Image\n",
    "img_license_plate = '9กด 1881 กรุงเทพมหานคร'\n",
    "img_camera = 'ad7de137-9287-402a-8b70-53684d96c88f'\n",
    "img_upload = upload_response['uploadId']\n",
    "notify_response = send_notify(img_license_plate, img_camera, img_upload)\n",
    "print(\"Send Notify with Image response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "พบทั้งหมด 1402 รูป → Train=981, Val=280, Test=141\n",
      "✅ แบ่ง dataset เสร็จแล้ว → อยู่ใน: datasets/YOLO\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# ใช้สำหรับแบ่ง dataset เป็น train/val/test\n",
    "# -------------------------------\n",
    "images_dir = \"data/images_all\"      # โฟลเดอร์เก็บภาพทั้งหมด (เช่น D:\\yolo\\Project_2\\data\\images_all)\n",
    "labels_dir = \"data/labels_all\"      # โฟลเดอร์เก็บ labels ทั้งหมด (เช่น D:\\yolo\\Project_2\\data\\labels_all)\n",
    "\n",
    "output_base = \"datasets/YOLO\"       # โฟลเดอร์สำหรับ train/val/test\n",
    "split_ratio = (0.7, 0.2, 0.1)       # train, val, test\n",
    "\n",
    "# -------------------------------\n",
    "# สร้างโฟลเดอร์ input ถ้าไม่มี\n",
    "# -------------------------------\n",
    "if not os.path.exists(images_dir):\n",
    "    os.makedirs(images_dir)\n",
    "    print(f\"⚠️ สร้างโฟลเดอร์ '{images_dir}' แล้ว (ตอนนี้ว่างเปล่า) → กรุณาใส่ไฟล์ภาพก่อน\")\n",
    "\n",
    "if not os.path.exists(labels_dir):\n",
    "    os.makedirs(labels_dir)\n",
    "    print(f\"⚠️ สร้างโฟลเดอร์ '{labels_dir}' แล้ว (ตอนนี้ว่างเปล่า) → กรุณาใส่ไฟล์ labels ก่อน\")\n",
    "\n",
    "# -------------------------------\n",
    "# สร้างโฟลเดอร์ output (images + labels + split)\n",
    "# -------------------------------\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    os.makedirs(os.path.join(output_base, \"images\", split), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_base, \"labels\", split), exist_ok=True)\n",
    "\n",
    "# -------------------------------\n",
    "# รวมรายชื่อไฟล์ภาพ\n",
    "# -------------------------------\n",
    "images = [f for f in os.listdir(images_dir) if f.lower().endswith((\".jpg\", \".png\"))]\n",
    "\n",
    "if not images:\n",
    "    print(f\"⚠️ ไม่พบไฟล์ภาพใน '{images_dir}' → กรุณาใส่ภาพก่อน\")\n",
    "    exit()\n",
    "\n",
    "import random\n",
    "random.shuffle(images)\n",
    "\n",
    "n_total = len(images)\n",
    "n_train = int(split_ratio[0] * n_total)\n",
    "n_val = int(split_ratio[1] * n_total)\n",
    "n_test = n_total - n_train - n_val\n",
    "\n",
    "print(f\"พบทั้งหมด {n_total} รูป → Train={n_train}, Val={n_val}, Test={n_test}\")\n",
    "\n",
    "# -------------------------------\n",
    "# ฟังก์ชันย้ายไฟล์\n",
    "# -------------------------------\n",
    "import shutil\n",
    "def move_files(file_list, split):\n",
    "    for img_file in file_list:\n",
    "        src_img = os.path.join(images_dir, img_file)\n",
    "        dst_img = os.path.join(output_base, \"images\", split, img_file)\n",
    "\n",
    "        # path ของ label (ชื่อเดียวกันแต่ .txt)\n",
    "        label_file = os.path.splitext(img_file)[0] + \".txt\"\n",
    "        src_lbl = os.path.join(labels_dir, label_file)\n",
    "        dst_lbl = os.path.join(output_base, \"labels\", split, label_file)\n",
    "\n",
    "        # copy ภาพ\n",
    "        shutil.copy(src_img, dst_img)\n",
    "\n",
    "        # copy label ถ้ามี\n",
    "        if os.path.exists(src_lbl):\n",
    "            shutil.copy(src_lbl, dst_lbl)\n",
    "        else:\n",
    "            print(f\"⚠️ ไม่มี label สำหรับ {img_file}\")\n",
    "\n",
    "# -------------------------------\n",
    "# แบ่ง dataset\n",
    "# -------------------------------\n",
    "move_files(images[:n_train], \"train\")\n",
    "move_files(images[n_train:n_train+n_val], \"val\")\n",
    "move_files(images[n_train+n_val:], \"test\")\n",
    "\n",
    "print(\"✅ แบ่ง dataset เสร็จแล้ว → อยู่ใน:\", output_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.206 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.201  Python-3.10.18 torch-2.0.1+cu118 CUDA:0 (NVIDIA GeForce GTX 1060, 6144MiB)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch._C' has no attribute '_has_mps'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[17], line 21\u001b[0m\n",
      "\u001b[0;32m     18\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolov8s.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# small model, VRAM 8GB ยังรองรับ\u001b[39;00m\n",
      "\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n",
      "\u001b[1;32m---> 21\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_yaml\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m560\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# ขนาดภาพใหญ่ขึ้น\u001b[39;49;00m\n",
      "\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# เพิ่ม batch size ให้ใช้ RAM 32GB\u001b[39;49;00m\n",
      "\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mplate_detector\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# เพิ่มความแม่น\u001b[39;49;00m\n",
      "\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# ใช้ GPU\u001b[39;49;00m\n",
      "\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhalf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# FP16 ลด VRAM\u001b[39;49;00m\n",
      "\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\n",
      "\u001b[0;32m     31\u001b[0m \u001b[43m)\u001b[49m\n",
      "\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# ทดสอบโมเดล\u001b[39;00m\n",
      "\u001b[0;32m     34\u001b[0m results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(\n",
      "\u001b[0;32m     35\u001b[0m     source\u001b[38;5;241m=\u001b[39mimages_dir,\n",
      "\u001b[0;32m     36\u001b[0m     save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "\u001b[0;32m     37\u001b[0m     conf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m\n",
      "\u001b[0;32m     38\u001b[0m )\n",
      "\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ultralytics\\engine\\model.py:795\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    792\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;32m    793\u001b[0m     args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt_path\n",
      "\u001b[1;32m--> 795\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m (trainer \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_smart_load(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrainer\u001b[39m\u001b[38;5;124m\"\u001b[39m))(overrides\u001b[38;5;241m=\u001b[39margs, _callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks)\n",
      "\u001b[0;32m    796\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# manually set model only if not resuming\u001b[39;00m\n",
      "\u001b[0;32m    797\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mget_model(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39myaml)\n",
      "\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ultralytics\\models\\yolo\\detect\\train.py:65\u001b[0m, in \u001b[0;36mDetectionTrainer.__init__\u001b[1;34m(self, cfg, overrides, _callbacks)\u001b[0m\n",
      "\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, cfg\u001b[38;5;241m=\u001b[39mDEFAULT_CFG, overrides: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, _callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[0;32m     57\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m     58\u001b[0m \u001b[38;5;124;03m    Initialize a DetectionTrainer object for training YOLO object detection model training.\u001b[39;00m\n",
      "\u001b[0;32m     59\u001b[0m \n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m     63\u001b[0m \u001b[38;5;124;03m        _callbacks (list, optional): List of callback functions to be executed during training.\u001b[39;00m\n",
      "\u001b[0;32m     64\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_callbacks\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ultralytics\\engine\\trainer.py:132\u001b[0m, in \u001b[0;36mBaseTrainer.__init__\u001b[1;34m(self, cfg, overrides, _callbacks)\u001b[0m\n",
      "\u001b[0;32m    130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;32m    131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplots \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[1;32m--> 132\u001b[0m init_seeds(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mseed \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m RANK, deterministic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdeterministic)\n",
      "\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# Dirs\u001b[39;00m\n",
      "\u001b[0;32m    135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m=\u001b[39m get_save_dir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs)\n",
      "\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ultralytics\\utils\\torch_utils.py:625\u001b[0m, in \u001b[0;36minit_seeds\u001b[1;34m(seed, deterministic)\u001b[0m\n",
      "\u001b[0;32m    620\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mModelEMA\u001b[39;00m:\n",
      "\u001b[0;32m    621\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m    622\u001b[0m \u001b[38;5;124;03m    Updated Exponential Moving Average (EMA) implementation.\u001b[39;00m\n",
      "\u001b[0;32m    623\u001b[0m \n",
      "\u001b[0;32m    624\u001b[0m \u001b[38;5;124;03m    Keeps a moving average of everything in the model state_dict (parameters and buffers).\u001b[39;00m\n",
      "\u001b[1;32m--> 625\u001b[0m \u001b[38;5;124;03m    For EMA details see References.\u001b[39;00m\n",
      "\u001b[0;32m    626\u001b[0m \n",
      "\u001b[0;32m    627\u001b[0m \u001b[38;5;124;03m    To disable EMA set the `enabled` attribute to `False`.\u001b[39;00m\n",
      "\u001b[0;32m    628\u001b[0m \n",
      "\u001b[0;32m    629\u001b[0m \u001b[38;5;124;03m    Attributes:\u001b[39;00m\n",
      "\u001b[0;32m    630\u001b[0m \u001b[38;5;124;03m        ema (nn.Module): Copy of the model in evaluation mode.\u001b[39;00m\n",
      "\u001b[0;32m    631\u001b[0m \u001b[38;5;124;03m        updates (int): Number of EMA updates.\u001b[39;00m\n",
      "\u001b[0;32m    632\u001b[0m \u001b[38;5;124;03m        decay (function): Decay function that determines the EMA weight.\u001b[39;00m\n",
      "\u001b[0;32m    633\u001b[0m \u001b[38;5;124;03m        enabled (bool): Whether EMA is enabled.\u001b[39;00m\n",
      "\u001b[0;32m    634\u001b[0m \n",
      "\u001b[0;32m    635\u001b[0m \u001b[38;5;124;03m    References:\u001b[39;00m\n",
      "\u001b[0;32m    636\u001b[0m \u001b[38;5;124;03m        - https://github.com/rwightman/pytorch-image-models\u001b[39;00m\n",
      "\u001b[0;32m    637\u001b[0m \u001b[38;5;124;03m        - https://www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage\u001b[39;00m\n",
      "\u001b[0;32m    638\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;32m    640\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9999\u001b[39m, tau\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m, updates\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n",
      "\u001b[0;32m    641\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m    642\u001b[0m \u001b[38;5;124;03m        Initialize EMA for 'model' with given arguments.\u001b[39;00m\n",
      "\u001b[0;32m    643\u001b[0m \n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m    648\u001b[0m \u001b[38;5;124;03m            updates (int, optional): Initial number of updates.\u001b[39;00m\n",
      "\u001b[0;32m    649\u001b[0m \u001b[38;5;124;03m        \"\"\"\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\random.py:44\u001b[0m, in \u001b[0;36mmanual_seed\u001b[1;34m(seed)\u001b[0m\n",
      "\u001b[0;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\mps\\__init__.py:71\u001b[0m, in \u001b[0;36mmanual_seed\u001b[1;34m(seed)\u001b[0m\n",
      "\u001b[0;32m     62\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sets the seed for generating random numbers.\u001b[39;00m\n",
      "\u001b[0;32m     63\u001b[0m \n",
      "\u001b[0;32m     64\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n",
      "\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    seed (int): The desired seed.\u001b[39;00m\n",
      "\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# the torch.mps.manual_seed() can be called from the global\u001b[39;00m\n",
      "\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# torch.manual_seed() in torch/random.py. So we need to make\u001b[39;00m\n",
      "\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# sure mps is available (otherwise we just return without\u001b[39;00m\n",
      "\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# erroring out)\u001b[39;00m\n",
      "\u001b[1;32m---> 71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_has_mps\u001b[49m:\n",
      "\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[0;32m     73\u001b[0m seed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(seed)\n",
      "\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch._C' has no attribute '_has_mps'"
     ]
    }
   ],
   "source": [
    "images_dir = \"cartest\"  \n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "data_yaml  = \"datasets/YOLO/data.yaml\"\n",
    "# -------------------------------\n",
    "\n",
    "\n",
    "# เลือกโมเดล\n",
    "model = YOLO(\"yolov8s.pt\")  # small model, VRAM 8GB ยังรองรับ\n",
    "\n",
    "# Train\n",
    "model.train(\n",
    "    data=data_yaml,\n",
    "    epochs=100,\n",
    "    imgsz=560,       # ขนาดภาพใหญ่ขึ้น\n",
    "    batch=8,        \n",
    "    name=\"plate_detector\",\n",
    "    augment=True,    # เพิ่มความแม่น\n",
    "    device=0 ,         # ใช้ GPU\n",
    "    half=True     # FP16 ลด VRAM\n",
    "    \n",
    ")\n",
    "\n",
    "# ทดสอบโมเดล\n",
    "results = model.predict(\n",
    "    source=images_dir,\n",
    "    save=True,\n",
    "    conf=0.5\n",
    ")\n",
    "print(\"✅ Prediction finished, check runs/detect/plate_detector/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ EasyOCR_ALPR loaded (GPU=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-18 14:34:19.965 python[7088:10370004] 2025-10-18 14:34:19.965048 [W:onnxruntime:, coreml_execution_provider.cc:113 GetCapability] CoreMLExecutionProvider::GetCapability, number of partitions supported by CoreML: 7 number of nodes in the graph: 693 number of nodes supported by CoreML: 675\n",
      "INFO:open_image_models.detection.core.yolo_v9.inference:Using ONNX Runtime with ['CoreMLExecutionProvider', 'AzureExecutionProvider', 'CPUExecutionProvider'] provider(s)\n",
      "INFO:open_image_models.detection.pipeline.license_plate:Initialized LicensePlateDetector with model /Users/tanitsak.le/.cache/open-image-models/yolo-v9-t-384-license-plate-end2end/yolo-v9-t-384-license-plates-end2end.onnx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ เริ่มระบบ (ตรวจ Presence ทุก 3.0 วิ, จอดนานเกิน 5.0 วิ). กด q เพื่อออก\n",
      "\n",
      "--- ตรวจหา Presence เวลา: 2025-10-18T14:34:21.864060 ---\n",
      "  ไม่พบ Presence (ไม่มีรถ)\n",
      "\n",
      "--- ตรวจหา Presence เวลา: 2025-10-18T14:34:24.800752 ---\n",
      "  ไม่พบ Presence (ไม่มีรถ)\n",
      "\n",
      "--- ตรวจหา Presence เวลา: 2025-10-18T14:34:27.805154 ---\n",
      "  ไม่พบ Presence (ไม่มีรถ)\n",
      "\n",
      "--- ตรวจหา Presence เวลา: 2025-10-18T14:34:30.823568 ---\n",
      "  ไม่พบ Presence (ไม่มีรถ)\n",
      "❌ ไม่สามารถอ่าน frame ได้ (end of video or camera error). หยุดการทำงาน.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Parking-watch simulator:\n",
    "- รันกล้องต่อเนื่อง\n",
    "- ตรวจหา \"การมีอยู่\" (presence) ของ plate ทุก 4 วินาที (YOLO only)\n",
    "- ถ้าไม่มีรถ -> รีเซ็ตตัวจับเวลา\n",
    "- ถ้ามีรถ (คันใดก็ได้) -> เริ่มจับเวลา\n",
    "- ถ้าเจอรถต่อเนื่อง (คันใดก็ได้) และเวลาตั้งแต่เจอครั้งแรก >= 60s\n",
    "  -> \"ณ วินาทีนั้น\" ค่อยสั่งอ่านทะเบียน (OCR)\n",
    "  -> แคปภาพทั้งคัน + print บันทึก\n",
    "  -> [NEW] ส่ง API แจ้งเตือน\n",
    "- พิมพ์สถานะทั้งหมด (no DB, no network)\n",
    "\"\"\"\n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import difflib\n",
    "from ultralytics import YOLO\n",
    "from datetime import datetime\n",
    "import base64  # <--- [NEW] Import\n",
    "import requests # <--- [NEW] Import\n",
    "\n",
    "# ---------------------------- fast_alpr import ----------------------------\n",
    "try:\n",
    "    from fast_alpr.alpr import ALPR, BaseOCR, OcrResult\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"❌ fast_alpr import failed: {e}\\nInstall with: pip install fast-alpr\")\n",
    "\n",
    "# === [NEW] Import for API ===\n",
    "try:\n",
    "    from requests_toolbelt.multipart.encoder import MultipartEncoder\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"❌ requests_toolbelt import failed: {e}\\nInstall with: pip install requests-toolbelt\")\n",
    "# ============================\n",
    "\n",
    "# ---------------------------- จังหวัดไทย ----------------------------\n",
    "thai_provinces = [\n",
    "    \"กรุงเทพมหานคร\", \"กระบี่\", \"กาญจนบุรี\", \"กาฬสินธุ์\", \"กำแพงเพชร\",\n",
    "    \"ขอนแก่น\", \"จันทบุรี\", \"ฉะเชิงเทรา\", \"ชลบุรี\", \"ชัยนาท\",\n",
    "    \"ชัยภูมิ\", \"ชุมพร\", \"เชียงราย\", \"เชียงใหม่\", \"ตรัง\",\n",
    "    \"ตราด\", \"ตาก\", \"นครนายก\", \"นครปฐม\", \"นครพนม\",\n",
    "    \"นครราชสีมา\", \"นครศรีธรรมราช\", \"นครสวรรค์\", \"นนทบุรี\", \"นราธิวาส\",\n",
    "    \"น่าน\", \"บึงกาฬ\", \"บุรีรัมย์\", \"ปทุมธานี\", \"ประจวบคีรีขันธ์\",\n",
    "    \"ปราจีนบุรี\", \"ปัตตานี\", \"พระนครศรีอยุธยา\", \"พังงา\", \"พัทลุง\",\n",
    "    \"พิจิตร\", \"พิษณุโลก\", \"เพชรบุรี\", \"เพชรบูรณ์\", \"แพร่\",\n",
    "    \"พะเยา\", \"ภูเก็ต\", \"มหาสารคาม\", \"มุกดาหาร\", \"แม่ฮ่องสอน\",\n",
    "    \"ยะลา\", \"ร้อยเอ็ด\", \"ระนอง\", \"ระยอง\",\n",
    "    \"ราชบุรี\", \"ลพบุรี\", \"ลำปาง\", \"ลำพูน\", \"เลย\",\n",
    "    \"ศรีสะเกษ\", \"สกลนคร\", \"สงขลา\", \"สตูล\", \"สมุทรปราการ\",\n",
    "    \"สมุทรสงคราม\", \"สมุทรสาคร\", \"สระแก้ว\", \"สระบุรี\", \"สิงห์บุรี\",\n",
    "    \"สุโขทัย\", \"สุพรรณบุรี\", \"สุราษฎร์ธานี\", \"สุรินทร์\", \"หนองคาย\",\n",
    "    \"หนองบัวลำภู\", \"อ่างทอง\", \"อำนาจเจริญ\", \"อุดรธานี\", \"อุตรดิตถ์\",\n",
    "    \"อุทัยธานี\", \"อุบลราชธานี\", \"ประเทศไทย\"\n",
    "]\n",
    "\n",
    "def correct_province(text):\n",
    "    if not text:\n",
    "        return None\n",
    "    match = difflib.get_close_matches(text, thai_provinces, n=1, cutoff=0.3)\n",
    "    return match[0] if match else None\n",
    "\n",
    "# ---------------------------- OCR Engine ----------------------------\n",
    "GPU_AVAILABLE = torch.cuda.is_available()\n",
    "\n",
    "class EasyOCR_ALPR(BaseOCR):\n",
    "    def __init__(self, lang_list=['th','en'], min_conf=0.1):\n",
    "        import easyocr\n",
    "        self.reader = easyocr.Reader(lang_list, gpu=GPU_AVAILABLE)\n",
    "        self.min_conf = min_conf\n",
    "        print(f\"✅ EasyOCR_ALPR loaded (GPU={GPU_AVAILABLE})\")\n",
    "\n",
    "    def predict(self, image: np.ndarray):\n",
    "        \n",
    "        # === [FIX] แก้ไข Bug การประมวลผลซ้ำซ้อน ===\n",
    "        # ถ้าภาพเป็น 3 channel (BGR) ให้ประมวลผล (Grayscale, CLAHE)\n",
    "        if len(image.shape) == 3:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            gray = cv2.bilateralFilter(gray, 6, 45, 45)\n",
    "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "            processed_image = clahe.apply(gray)\n",
    "        # ถ้าภาพเป็น 1 channel (Grayscale หรือ Binary) ให้ใช้ทันที\n",
    "        else:\n",
    "            processed_image = image\n",
    "        # ==========================================\n",
    "\n",
    "        ocr_results = self.reader.readtext(processed_image)\n",
    "        results = []\n",
    "        for r in ocr_results:\n",
    "            bbox, text, conf = r if len(r)==3 else (None, r[1], 1.0)\n",
    "            if conf >= self.min_conf and text.strip():\n",
    "                results.append(OcrResult(text=text.strip(), confidence=float(conf)))\n",
    "        return results\n",
    "\n",
    "# ---------------------------- helpers (plate extraction + enhance) ----------------------------\n",
    "def correct_common_thai_ocr_errors(text):\n",
    "    # แก้ไขการจับคู่ที่ผิด\n",
    "    corrections = {\n",
    "        \"ญณ\": \"ฌฌ\", \"ญญ\": \"ฌฌ\", \"ญ\": \"ฌ\"\n",
    "    }\n",
    "    for wrong, right in corrections.items():\n",
    "        text = text.replace(wrong, right)\n",
    "    return text\n",
    "\n",
    "def upscale_image(img, scale=2): \n",
    "    # ลด scale ลงหน่อย เพื่อให้ภาพไม่ใหญ่เกินไปในการ debug\n",
    "    h, w = img.shape[:2]\n",
    "    return cv2.resize(img, (w*scale, h*scale), interpolation=cv2.INTER_LANCZOS4)\n",
    "\n",
    "def extract_province_from_text(text):\n",
    "    candidates = re.split(r\"[\\s\\n]+\", text)\n",
    "    for word in candidates:\n",
    "        match = difflib.get_close_matches(word, thai_provinces, n=1, cutoff=0.25)\n",
    "        if match:\n",
    "            return match[0]\n",
    "    return None\n",
    "\n",
    "# === ปรับปรุง Regex ให้อนุญาตตัวอักษรภาษาอังกฤษ ===\n",
    "def extract_thai_license_plate(text):\n",
    "    cleaned = re.sub(r\"[\\n\\r]+\", \" \", text)\n",
    "    \n",
    "    # อนุญาต ก-ฮ, a-z, A-Z, 0-9 (เผื่อ OCR อ่านไทยเป็นอังกฤษ)\n",
    "    cleaned = re.sub(r\"[^ก-ฮa-zA-Z0-9\\s\\-\\.]\", \"\", cleaned) \n",
    "    \n",
    "    cleaned = re.sub(r\"\\s+\", \" \", cleaned).strip()\n",
    "    \n",
    "    # อนุญาต ก-ฮ และ a-zA-Z ในส่วนตัวอักษรของป้าย\n",
    "    pattern = (\n",
    "        r\"([0-9]{0,2}\\s*[ก-ฮa-zA-Z]{1,3}[\\s\\-\\.]*\\d{1,4})\"     # หมายเลขทะเบียน\n",
    "        r\"[\\s\\n]*\"\n",
    "        r\"(?:จังหวัด)?\\s*([ก-ฮ]{2,20})?\"                 # จังหวัด (optional, ยังคงเป็น ก-ฮ)\n",
    "    )\n",
    "    \n",
    "    matches = re.findall(pattern, cleaned)\n",
    "    results = []\n",
    "    for plate, province in matches:\n",
    "        plate = re.sub(r\"[\\s\\-\\.]\", \"\", plate)\n",
    "        province = province.strip() if province else None\n",
    "        if province:\n",
    "            best_match = difflib.get_close_matches(province, thai_provinces, n=1, cutoff=0.25)\n",
    "            province = best_match[0] if best_match else None\n",
    "        results.append({\"plate\": plate, \"province\": province})\n",
    "    return results\n",
    "\n",
    "# === ปรับปรุง Enhance Function (สำคัญมาก) ===\n",
    "# ให้คืนค่าเป็น Grayscale แทน Binary\n",
    "def enhance_for_ocr(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if len(img.shape)==3 else img.copy()\n",
    "    \n",
    "    # ใช้ Bilateral Filter เพื่อลด Noise แต่ยังคงขอบ (Edge) ไว้\n",
    "    gray = cv2.bilateralFilter(gray, 5, 80, 80)\n",
    "    \n",
    "    # ใช้ CLAHE เพื่อเพิ่ม Contrast ในพื้นที่เล็กๆ\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(5,5))\n",
    "    gray = clahe.apply(gray)\n",
    "    \n",
    "    # อาจจะเบลอนิดหน่อยเพื่อลด noise ที่อาจเพิ่มจาก CLAHE\n",
    "    gray = cv2.GaussianBlur(gray, (3,3), 0)\n",
    "    \n",
    "    # ขยายภาพให้ใหญ่ขึ้น (สำคัญมากสำหรับ OCR)\n",
    "    gray = cv2.resize(gray, None, fx=3.5, fy=3.5, interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    # ❌ ไม่ใช้ adaptiveThreshold ❌\n",
    "    # ❌ ไม่ใช้ sharpen ❌\n",
    "    \n",
    "    # คืนค่าเป็น Grayscale image ที่ Enhance แล้ว\n",
    "    return gray\n",
    "# ===================================================\n",
    "\n",
    "def safe_crop(img,x1,y1,x2,y2,pad=5):\n",
    "    h,w=img.shape[:2]\n",
    "    x1=max(0,x1-pad)\n",
    "    y1=max(0,y1-pad)\n",
    "    x2=min(w,x2+pad)\n",
    "    y2=min(h,y2+pad)\n",
    "    return img[y1:y2,x1:x2]\n",
    "\n",
    "# === API Helper Function ===\n",
    "def upload_image_base64(image_base64: str, filename: str = \"image.jpg\"):\n",
    "    # ✅ แปลง base64 string -> bytes\n",
    "    try:\n",
    "        image_bytes = base64.b64decode(image_base64)\n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Error decoding base64: {e}\")\n",
    "        return {\"error\": \"base64 decode error\", \"uploadId\": None}\n",
    "\n",
    "    # ✅ เตรียม multipart/form-data\n",
    "    multipart_data = MultipartEncoder(\n",
    "        fields={'image': (filename, image_bytes, 'image/jpeg')}\n",
    "    )\n",
    "\n",
    "    headers = {\n",
    "        \"X-API-KEY\": API_KEY,\n",
    "        'Content-Type': multipart_data.content_type\n",
    "    }\n",
    "\n",
    "    # ✅ ส่ง request\n",
    "    try:\n",
    "        response = requests.post(API_UPLOAD_URL, data=multipart_data, headers=headers, timeout=10.0)\n",
    "        if response.status_code == 201:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"  ❌ Error uploading image: {response.status_code} {response.text}\")\n",
    "            return {\"error\": \"upload failed\", \"uploadId\": None}\n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Exception during image upload: {e}\")\n",
    "        return {\"error\": str(e), \"uploadId\": None}\n",
    "# ==================================\n",
    "\n",
    "# ---------------------------- Initialize ALPR & YOLO ----------------------------\n",
    "ocr_engine = EasyOCR_ALPR(lang_list=['th','en'])\n",
    "alpr = ALPR(ocr=ocr_engine)   # ใช้งาน fast_alpr wrapper ของคุณ\n",
    "YOLO_WEIGHTS = \"runs/detect/plate_detector/weights/best.pt\"  # เปลี่ยนให้ถูกต้อง\n",
    "model = YOLO(YOLO_WEIGHTS)\n",
    "\n",
    "# ---------------------------- Simulation / monitoring params ----------------------------\n",
    "\n",
    "source = \"demos/hard.mp4\" # เปลี่ยนเป็นไฟล์วิดีโอ \"car001.mp4\" หรือ 0 สำหรับกล้อง\n",
    "CHECK_INTERVAL = 3.0  # วินาที — ตรวจหา \"presence\" ทุก 3 วิ\n",
    "LONG_STAY_THRESHOLD = 5.0 # วินาที — ถ้า \"presence\" นานเกิน 5 วิ => long stay\n",
    "OUTPUT_DIR = \"output_longstay\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# === [NEW] API Constants ===\n",
    "API_UPLOAD_URL = \"http://ec2-54-87-52-160.compute-1.amazonaws.com/media/v1/upload/image\"\n",
    "API_NOTIFY_URL = \"http://ec2-54-87-52-160.compute-1.amazonaws.com/notify/v1/send\"\n",
    "API_KEY = \"123456\"\n",
    "# CAMERA_ID = \"e8564251-3746-4599-846c-46ea8703b7a3\" #ศูนย์ฝึก\n",
    "CAMERA_ID = \"2ec15a48-c819-494c-a807-5c0f41ebaf36\" #อโศก\n",
    "# ===========================\n",
    "\n",
    "# === [LOGIC CHANGE] A tracking state based on \"presence\" ===\n",
    "presence_first_seen = None       # datetime ของการพบ \"รถ\" (คันใดก็ได้) ครั้งแรก\n",
    "presence_last_seen = None        # datetime ของการพบ \"รถ\" (คันใดก็ได้) ล่าสุด\n",
    "last_detected_plate_text = \"N/A\" # สำหรับแสดงบนภาพสด\n",
    "\n",
    "# ---------------------------- Main loop ----------------------------\n",
    "cap = cv2.VideoCapture(source)\n",
    "last_check = 0.0\n",
    "\n",
    "print(f\"✅ เริ่มระบบ (ตรวจ Presence ทุก {CHECK_INTERVAL} วิ, จอดนานเกิน {LONG_STAY_THRESHOLD} วิ). กด q เพื่อออก\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"❌ ไม่สามารถอ่าน frame ได้ (end of video or camera error). หยุดการทำงาน.\")\n",
    "        break\n",
    "\n",
    "    now = time.time()\n",
    "    display_frame = frame.copy() # ใช้สำเนาของ frame สำหรับการแสดงผล\n",
    "\n",
    "    cv2.imshow(\"Camera Live\", frame)\n",
    "    # ตรวจในช่วง interval เท่านั้น\n",
    "    if now - last_check < CHECK_INTERVAL:\n",
    "        # ยังไม่ถึงเวลาเช็กใหม่ แต่ให้แสดงผล YOLO box ล่าสุดและป้ายที่อ่านได้\n",
    "        if 'last_boxes' in locals() and len(last_boxes) > 0:\n",
    "            for box in last_boxes:\n",
    "                x1, y1, x2, y2 = map(int, box)\n",
    "                cv2.rectangle(display_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                cv2.putText(display_frame, last_detected_plate_text, (x1, y1 - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        \n",
    "        # แสดงเวลาที่ elapsed (ถ้ามีการจับเวลาอยู่)\n",
    "        if presence_first_seen is not None:\n",
    "            current_elapsed = (datetime.now() - presence_first_seen).total_seconds()\n",
    "            cv2.putText(display_frame, f\"Elapsed: {current_elapsed:.1f}s\", (10, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow(\"ALPR Live\", display_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            print(\"ออกโดยผู้ใช้\")\n",
    "            break\n",
    "        continue\n",
    "    \n",
    "    # === ส่วนนี้จะทำงานทุกๆ CHECK_INTERVAL วินาที ===\n",
    "    last_check = now\n",
    "    check_dt = datetime.now()\n",
    "    print(f\"\\n--- ตรวจหา Presence เวลา: {check_dt.isoformat()} ---\")\n",
    "\n",
    "    # 1. รัน YOLO (Fast) เพื่อดูว่ามี \"กล่อง\" ป้ายทะเบียนหรือไม่\n",
    "    results = model.predict(frame, conf=0.4, verbose=False) \n",
    "    boxes = results[0].boxes.xyxy.cpu().numpy() if len(results) > 0 else []\n",
    "    last_boxes = boxes # เก็บ box ล่าสุดไว้สำหรับแสดงผลในช่วงพัก\n",
    "    \n",
    "    is_plate_present = len(boxes) > 0\n",
    "    current_frame_plate_text = \"N/A\" # สำหรับแสดงบนภาพสดในรอบนี้\n",
    "\n",
    "    # === ตรวจสอบตาม \"Presence\" (การมีอยู่) ===\n",
    "\n",
    "    if is_plate_present:\n",
    "        # 2. ถ้ามีรถ\n",
    "        if presence_first_seen is None:\n",
    "            # 2.1 ถ้าเพิ่งเจอครั้งแรก -> เริ่มจับเวลา\n",
    "            presence_first_seen = check_dt\n",
    "            presence_last_seen = check_dt\n",
    "            print(f\"  พบ Presence (มีรถ), เริ่มจับเวลา... {presence_first_seen.isoformat()}\")\n",
    "        else:\n",
    "            # 2.2 ถ้าเจอต่อเนื่อง -> อัปเดตเวลา และเช็กว่านานเกินไปหรือยัง\n",
    "            presence_last_seen = check_dt\n",
    "            elapsed = (presence_last_seen - presence_first_seen).total_seconds()\n",
    "            print(f\"  พบ Presence ต่อเนื่อง (elapsed = {elapsed:.1f} s)\")\n",
    "\n",
    "            if elapsed >= LONG_STAY_THRESHOLD:\n",
    "                # 3. [TRIGGER] ถ้านานเกิน Threshold -> \"ณ จุดนี้\" ค่อยสั่ง OCR (Slow)\n",
    "                print(f\"  (!) เวลาเกิน {LONG_STAY_THRESHOLD} s. ทำการอ่านป้ายทะเบียนเดี๋ยวนี้...\")\n",
    "\n",
    "                detected_plate = None\n",
    "                detected_province = None\n",
    "                \n",
    "                # เก็บภาพ crop_enh ที่ดีที่สุดไว้\n",
    "                best_crop_enh = None\n",
    "                best_plate_text = None\n",
    "                best_plate_province = None\n",
    "                \n",
    "                # === [MOVED] ย้ายโค้ด OCR มาไว้ตรงนี้ ===\n",
    "                for i, box in enumerate(boxes): # เพิ่ม i สำหรับตั้งชื่อไฟล์\n",
    "                    x1, y1, x2, y2 = map(int, box)\n",
    "                    h_box = y2 - y1\n",
    "                    extra = int(h_box * 0.8)\n",
    "                    y2_expanded = min(frame.shape[0], y2 + extra)\n",
    "                    crop = safe_crop(frame, x1, y1, x2, y2_expanded, pad=6)\n",
    "                    if crop.size == 0: continue\n",
    "\n",
    "                    crop_up = upscale_image(crop, scale=2)\n",
    "                    \n",
    "                    # ใช้ enhance_for_ocr ที่คืนค่า Grayscale\n",
    "                    crop_enh = enhance_for_ocr(crop_up) \n",
    "                    \n",
    "                    # รัน OCR ที่นี่ (เฉพาะเมื่อจำเป็น)\n",
    "                    ocr_results = ocr_engine.predict(crop_enh) \n",
    "                    \n",
    "                    texts = [r.text.strip() for r in ocr_results if hasattr(r, \"text\") and r.text.strip()]\n",
    "                    combined_text = \" \".join(texts)\n",
    "\n",
    "                    # === [DEBUG] พิมพ์ผลลัพธ์ดิบจาก OCR ===\n",
    "                    print(f\"    -> OCR Raw Text (Box {i}): '{combined_text}'\")\n",
    "                    # ======================================\n",
    "\n",
    "                    # ใช้ extract_thai_license_plate ที่แก้ไขแล้ว\n",
    "                    plate_results = extract_thai_license_plate(combined_text) \n",
    "                    \n",
    "                    if plate_results:\n",
    "                        plate_info = plate_results[0]\n",
    "                        current_detected_plate = plate_info.get('plate')\n",
    "                        current_detected_province = plate_info.get('province') or extract_province_from_text(combined_text)\n",
    "                        \n",
    "                        # เลือกป้ายแรกที่อ่านได้เป็น best_plate\n",
    "                        if current_detected_plate:\n",
    "                            best_plate_text = current_detected_plate\n",
    "                            best_plate_province = current_detected_province\n",
    "                            best_crop_enh = crop_enh.copy() # เก็บสำเนาภาพไว้\n",
    "                            print(f\"    -> อ่านทะเบียนได้: {best_plate_text} {best_plate_province or ''}\")\n",
    "                            break # เอาแค่ป้ายแรกที่อ่านได้\n",
    "                # === จบส่วน OCR ===\n",
    "\n",
    "                last_detected_plate_text = best_plate_text if best_plate_text else \"UNKNOWN\"\n",
    "\n",
    "                if best_plate_text:\n",
    "                    # 4. ถ้าอ่านป้ายได้ -> บันทึก\n",
    "                    timestamp_str = presence_last_seen.strftime('%Y%m%d_%H%M%S')\n",
    "                    # บันทึกภาพเต็ม\n",
    "                    fname_full = f\"{OUTPUT_DIR}/{best_plate_text}_{timestamp_str}_full.jpg\"\n",
    "                    cv2.imwrite(fname_full, frame)\n",
    "                    # บันทึกภาพป้ายทะเบียนที่ Enhance แล้ว (ตอนนี้เป็น Grayscale)\n",
    "                    fname_ocr_crop = f\"{OUTPUT_DIR}/{best_plate_text}_{timestamp_str}_ocr_crop.jpg\"\n",
    "                    cv2.imwrite(fname_ocr_crop, best_crop_enh)\n",
    "                    \n",
    "                    # === API INTEGRATION ===\n",
    "                    print(f\"  🚀 Preparing to send API notification for {best_plate_text}...\")\n",
    "                    \n",
    "                    # 1. Encode image to base64 (ใช้ frame = ภาพเต็ม)\n",
    "                    _, buffer = cv2.imencode('.jpg', frame) \n",
    "                    img_base64 = base64.b64encode(buffer).decode('utf-8')\n",
    "\n",
    "                    # 2. Upload image\n",
    "                    print(f\"    - Uploading image...\")\n",
    "                    upload_response = upload_image_base64(img_base64, filename=fname_full)\n",
    "                    upload_id = upload_response.get('uploadId') # ใช้ .get() เพื่อป้องกัน Error ถ้า key ไม่มี\n",
    "\n",
    "                    if upload_id:\n",
    "                        print(f\"    - Image uploaded, uploadId: {upload_id}\")\n",
    "                        # 3. Send notification\n",
    "                        payload = {\n",
    "                            \"licensePlate\": best_plate_text + (f\" {best_plate_province}\" if best_plate_province else \"\"),\n",
    "                            \"uploadId\": upload_id,\n",
    "                            \"cameraId\": CAMERA_ID\n",
    "                        }\n",
    "\n",
    "                        print(f\"    - Sending notification payload...\")\n",
    "                        try:\n",
    "                            response = requests.post(\n",
    "                                API_NOTIFY_URL,\n",
    "                                headers={\"X-API-KEY\": API_KEY},\n",
    "                                json=payload,\n",
    "                                timeout=10.0\n",
    "                            )\n",
    "                            if response.status_code == 200:\n",
    "                                print(\"    ✅ Notification API sent successfully.\")\n",
    "                            else:\n",
    "                                print(f\"    ❌ Notification API failed: {response.status_code} -> {response.text}\")\n",
    "                        except Exception as e:\n",
    "                            print(f\"    ⚠️ Exception during notification API call: {e}\")\n",
    "                    else:\n",
    "                        print(f\"    ❌ Skipping notification API call due to image upload failure.\")\n",
    "                    # ============================\n",
    "\n",
    "                    # === แสดงผลภาพ Crop ที่อ่านได้ (เหมือนเดิม) ===\n",
    "                    window_name = f\"OCR Result: {best_plate_text}\"\n",
    "                    cv2.imshow(window_name, best_crop_enh)\n",
    "                    cv2.waitKey(0) # รอให้ผู้ใช้กดปุ่ม\n",
    "                    cv2.destroyWindow(window_name) # ปิดหน้าต่างนี้\n",
    "                    # ==========================================\n",
    "\n",
    "                    print(f\"\\n>>> LONG STAY DETECTED: {best_plate_text}\")\n",
    "                    print(f\"    - first_seen: {presence_first_seen.isoformat()}\")\n",
    "                    print(f\"    - last_seen : {presence_last_seen.isoformat()}\")\n",
    "                    print(f\"    - elapsed   : {elapsed:.1f} seconds\")\n",
    "                    print(f\"    - saved full image: {fname_full}\")\n",
    "                    print(f\"    - saved OCR crop image: {fname_ocr_crop}\\n\")\n",
    "                    \n",
    "                    # <--- [NEW] แสดง CameraView และจบการทำงาน ---\n",
    "                    print(\"  (!) ดำเนินการเสร็จสิ้น, จบการทำงาน\")\n",
    "                    cv2.imshow(\"Camera Live\", frame) # แสดง CameraView ครั้งสุดท้าย\n",
    "                    cv2.waitKey(1) # ให้เวลา window update\n",
    "                    break # <--- จบ loop ทันที\n",
    "                    # -----------------------------------------------\n",
    "                    \n",
    "                else:\n",
    "                    # 4.1 ถ้าอ่านป้ายไม่ได้ (ณ วินาทีสุดท้าย)\n",
    "                    timestamp_str = presence_last_seen.strftime('%Y%m%d_%H%M%S')\n",
    "                    # บันทึกภาพเต็มแม้จะอ่านป้ายไม่ได้ก็ตาม\n",
    "                    fname_full = f\"{OUTPUT_DIR}/UNKNOWN_{timestamp_str}_full.jpg\"\n",
    "                    cv2.imwrite(fname_full, frame)\n",
    "                    \n",
    "                    print(f\"\\n>>> LONG STAY DETECTED (Unknown Plate)\")\n",
    "                    print(f\"    - first_seen: {presence_first_seen.isoformat()}\")\n",
    "                    print(f\"    - elapsed   : {elapsed:.1f} seconds\")\n",
    "                    print(f\"    - (ไม่สามารถอ่านป้ายทะเบียนได้ในจังหวะสุดท้าย)\")\n",
    "                    print(f\"    - saved full image (unknown plate): {fname_full}\\n\")\n",
    "                    \n",
    "                    # ถ้าต้องการเก็บ crop_enh ที่อ่านไม่ได้ด้วย (เพื่อ debug):\n",
    "                    if len(boxes) > 0: # ถ้ามี box แต่ OCR อ่านไม่ได้\n",
    "                        x1, y1, x2, y2 = map(int, boxes[0]) # เอา box แรก\n",
    "                        h_box = y2 - y1\n",
    "                        extra = int(h_box * 0.8)\n",
    "                        y2_expanded = min(frame.shape[0], y2 + extra)\n",
    "                        crop = safe_crop(frame, x1, y1, x2, y2_expanded, pad=6)\n",
    "                        if crop.size > 0:\n",
    "                            crop_up = upscale_image(crop, scale=2)\n",
    "                            temp_crop_enh = enhance_for_ocr(crop_up) # ใช้ตัว Enhance ใหม่\n",
    "                            fname_ocr_crop_unknown = f\"{OUTPUT_DIR}/UNKNOWN_{timestamp_str}_ocr_crop.jpg\"\n",
    "                            cv2.imwrite(fname_ocr_crop_unknown, temp_crop_enh)\n",
    "                            print(f\"    - saved OCR crop image (for debug): {fname_ocr_crop_unknown}\\n\")\n",
    "                            cv2.imshow(f\"OCR Crop (UNKNOWN)\", temp_crop_enh) # แสดงภาพให้เห็น\n",
    "                            cv2.waitKey(0) # รอให้ปิดหน้าต่างก่อนไปต่อ\n",
    "                            cv2.destroyWindow(f\"OCR Crop (UNKNOWN)\")\n",
    "                            \n",
    "                            # <--- แสดง CameraView และจบการทำงาน ---\n",
    "                            print(\"  (!) ดำเนินการเสร็จสิ้น (ไม่พบป้าย), จบการทำงาน\")\n",
    "                            cv2.imshow(\"Camera Live\", frame) # แสดง CameraView ครั้งสุดท้าย\n",
    "                            cv2.waitKey(1) # ให้เวลา window update\n",
    "                            break # <--- จบ loop ทันที\n",
    "                            # -----------------------------------------------\n",
    "\n",
    "                # 5. รีเซ็ตตัวจับเวลา เพื่อเริ่มรอบใหม่ (ส่วนนี้จะถูกข้ามไปถ้า break)\n",
    "                print(\"  รีเซ็ตตัวจับเวลา...\")\n",
    "                presence_first_seen = None\n",
    "                presence_last_seen = None\n",
    "    \n",
    "    else:\n",
    "        # 6. ถ้าไม่มีรถในเฟรมนี้\n",
    "        print(\"  ไม่พบ Presence (ไม่มีรถ)\")\n",
    "        if presence_first_seen is not None:\n",
    "            # 6.1 ถ้ารถเพิ่งหายไป -> รีเซ็ตตัวจับเวลา\n",
    "            print(\"  รถเป้าหมายหายไป รีเซ็ตตัวจับเวลา\")\n",
    "            presence_first_seen = None\n",
    "            presence_last_seen = None\n",
    "        last_detected_plate_text = \"N/A\" # รีเซ็ตข้อความป้ายทะเบียนที่แสดงบนภาพสด\n",
    "\n",
    "    # === แสดงผลบนภาพสด (ทุกๆ รอบของ Main loop) ===\n",
    "    # วาดกรอบป้ายทะเบียน (จาก YOLO ล่าสุด)\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        cv2.rectangle(display_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        # แสดงป้ายทะเบียนที่อ่านได้ (ถ้ามี)\n",
    "        if last_detected_plate_text != \"N/A\" and last_detected_plate_text != \"UNKNOWN\":\n",
    "            cv2.putText(display_frame, last_detected_plate_text, (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        \n",
    "    # แสดงเวลาที่ elapsed (ถ้ามีการจับเวลาอยู่)\n",
    "    if presence_first_seen is not None:\n",
    "        current_elapsed = (datetime.now() - presence_first_seen).total_seconds()\n",
    "        cv2.putText(display_frame, f\"Elapsed: {current_elapsed:.1f}s / {LONG_STAY_THRESHOLD:.1f}s\", (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    else:\n",
    "        cv2.putText(display_frame, \"No Presence\", (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow(\"ALPR Live\", display_frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        print(\"ออกโดยผู้ใช้\")\n",
    "        break\n",
    "\n",
    "# end main loopq\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "dl_564",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "livereveal": {
   "height": "100%",
   "margin": 0,
   "maxScale": 1,
   "minScale": 1,
   "scroll": true,
   "start_slideshow_at": "selected",
   "theme": "sky",
   "transition": "zoom",
   "width": "100%"
  },
  "toc": {
   "nav_menu": {
    "height": "369px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "457px",
    "left": "0px",
    "right": "968px",
    "top": "130px",
    "width": "214px"
   },
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
