{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import xml.etree.ElementTree as ET\n",
    "from ultralytics import YOLO\n",
    "import random\n",
    "import cv2\n",
    "import pytesseract\n",
    "import torch\n",
    "import easyocr\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import defaultdict, deque\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from requests_toolbelt.multipart.encoder import MultipartEncoder\n",
    "\n",
    "def get_def_headers():\n",
    "    return {\n",
    "        \"X-API-KEY\": \"123456\"\n",
    "    }\n",
    "\n",
    "def get_base_api():\n",
    "    return 'http://ec2-54-87-52-160.compute-1.amazonaws.com'\n",
    "\n",
    "\n",
    "# Camera id use for identify location of their cameras\n",
    "# please use these id below for testing:\n",
    "# ad7de137-9287-402a-8b70-53684d96c88f: Future park, Rangsit, Thanyaburi, Prachatipat, Pathum Thani\n",
    "# 2ec15a48-c819-494c-a807-5c0f41ebaf36: BTS Asok, Klongtoey Noei, Wattana, Bangkok\n",
    "# 0e76998d-0590-4679-924a-049f92ab0b81: Lotus Laksi, Bangkhen, Anusawaree, Bangkok\n",
    "\n",
    "\n",
    "# Send Notify API\n",
    "def send_notify(license_plate: str, camera_id: str, upload_id: str):\n",
    "    notify_api = get_base_api() + \"/notify/v1/send\"\n",
    "    notify_json = {\n",
    "        'licensePlate': license_plate,\n",
    "        'cameraId': camera_id,\n",
    "        'uploadId': upload_id\n",
    "    }\n",
    "    response = requests.post(notify_api, json=notify_json, headers=get_def_headers())\n",
    "    return response.json()\n",
    "\n",
    "# Upload Image API\n",
    "def upload_image(image_path):\n",
    "    upload_api = get_base_api() + \"/media/v1/upload/image\"\n",
    "    filename = os.path.basename(image_path)\n",
    "\n",
    "    with open(image_path, 'rb') as img_file:\n",
    "        multipart_data = MultipartEncoder(\n",
    "            fields={'image': (filename, img_file, 'image/jpeg')}\n",
    "        )\n",
    "        headers = get_def_headers()\n",
    "        headers['Content-Type'] = multipart_data.content_type\n",
    "        \n",
    "        response = requests.post(upload_api, data=multipart_data, headers=headers)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Send Notify without Image response: {'notifyId': 'c2a1390c-45e3-414b-a6fb-a530a0409b6d', 'status': 'PENDING'}\n"
     ]
    }
   ],
   "source": [
    "# Example Send Notify without Image\n",
    "no_img_license_plate = \"7กญ 3603 กรุงเทพมหานคร\"\n",
    "no_img_camera = \"ad7de137-9287-402a-8b70-53684d96c88f\"\n",
    "response = send_notify(no_img_license_plate, no_img_camera, '')\n",
    "print(\"Send Notify without Image response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Send Upload response: {'uploadId': '71bfe9c0-204f-4011-a1ed-6e81be8f386f', 'fileId': '5ff3a40a-513d-47c2-9d60-d0afacbf0e6f', 'filePath': '71bfe9c0-204f-4011-a1ed-6e81be8f386f/5ff3a40a-513d-47c2-9d60-d0afacbf0e6f.jpg', 'contentType': 'jpg', 'status': 'SUCCESS'}\n",
      "Send Notify with Image response: {'notifyId': 'c2a1390c-45e3-414b-a6fb-a530a0409b6d', 'status': 'PENDING'}\n"
     ]
    }
   ],
   "source": [
    "# Example Send Upload Image\n",
    "img_path = './runs/detect/predict4/car02.jpg'\n",
    "upload_response = upload_image(img_path)\n",
    "print(\"Send Upload response:\", upload_response)\n",
    "\n",
    "# Example Send Notify with Image\n",
    "img_license_plate = '9กด 1881 กรุงเทพมหานคร'\n",
    "img_camera = 'ad7de137-9287-402a-8b70-53684d96c88f'\n",
    "img_upload = upload_response['uploadId']\n",
    "notify_response = send_notify(img_license_plate, img_camera, img_upload)\n",
    "print(\"Send Notify with Image response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "พบทั้งหมด 1402 รูป → Train=981, Val=280, Test=141\n",
      "✅ แบ่ง dataset เสร็จแล้ว → อยู่ใน: datasets/YOLO\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# ใช้สำหรับแบ่ง dataset เป็น train/val/test\n",
    "# -------------------------------\n",
    "images_dir = \"data/images_all\"      # โฟลเดอร์เก็บภาพทั้งหมด (เช่น D:\\yolo\\Project_2\\data\\images_all)\n",
    "labels_dir = \"data/labels_all\"      # โฟลเดอร์เก็บ labels ทั้งหมด (เช่น D:\\yolo\\Project_2\\data\\labels_all)\n",
    "\n",
    "output_base = \"datasets/YOLO\"       # โฟลเดอร์สำหรับ train/val/test\n",
    "split_ratio = (0.7, 0.2, 0.1)       # train, val, test\n",
    "\n",
    "# -------------------------------\n",
    "# สร้างโฟลเดอร์ input ถ้าไม่มี\n",
    "# -------------------------------\n",
    "if not os.path.exists(images_dir):\n",
    "    os.makedirs(images_dir)\n",
    "    print(f\"⚠️ สร้างโฟลเดอร์ '{images_dir}' แล้ว (ตอนนี้ว่างเปล่า) → กรุณาใส่ไฟล์ภาพก่อน\")\n",
    "\n",
    "if not os.path.exists(labels_dir):\n",
    "    os.makedirs(labels_dir)\n",
    "    print(f\"⚠️ สร้างโฟลเดอร์ '{labels_dir}' แล้ว (ตอนนี้ว่างเปล่า) → กรุณาใส่ไฟล์ labels ก่อน\")\n",
    "\n",
    "# -------------------------------\n",
    "# สร้างโฟลเดอร์ output (images + labels + split)\n",
    "# -------------------------------\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    os.makedirs(os.path.join(output_base, \"images\", split), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_base, \"labels\", split), exist_ok=True)\n",
    "\n",
    "# -------------------------------\n",
    "# รวมรายชื่อไฟล์ภาพ\n",
    "# -------------------------------\n",
    "images = [f for f in os.listdir(images_dir) if f.lower().endswith((\".jpg\", \".png\"))]\n",
    "\n",
    "if not images:\n",
    "    print(f\"⚠️ ไม่พบไฟล์ภาพใน '{images_dir}' → กรุณาใส่ภาพก่อน\")\n",
    "    exit()\n",
    "\n",
    "import random\n",
    "random.shuffle(images)\n",
    "\n",
    "n_total = len(images)\n",
    "n_train = int(split_ratio[0] * n_total)\n",
    "n_val = int(split_ratio[1] * n_total)\n",
    "n_test = n_total - n_train - n_val\n",
    "\n",
    "print(f\"พบทั้งหมด {n_total} รูป → Train={n_train}, Val={n_val}, Test={n_test}\")\n",
    "\n",
    "# -------------------------------\n",
    "# ฟังก์ชันย้ายไฟล์\n",
    "# -------------------------------\n",
    "import shutil\n",
    "def move_files(file_list, split):\n",
    "    for img_file in file_list:\n",
    "        src_img = os.path.join(images_dir, img_file)\n",
    "        dst_img = os.path.join(output_base, \"images\", split, img_file)\n",
    "\n",
    "        # path ของ label (ชื่อเดียวกันแต่ .txt)\n",
    "        label_file = os.path.splitext(img_file)[0] + \".txt\"\n",
    "        src_lbl = os.path.join(labels_dir, label_file)\n",
    "        dst_lbl = os.path.join(output_base, \"labels\", split, label_file)\n",
    "\n",
    "        # copy ภาพ\n",
    "        shutil.copy(src_img, dst_img)\n",
    "\n",
    "        # copy label ถ้ามี\n",
    "        if os.path.exists(src_lbl):\n",
    "            shutil.copy(src_lbl, dst_lbl)\n",
    "        else:\n",
    "            print(f\"⚠️ ไม่มี label สำหรับ {img_file}\")\n",
    "\n",
    "# -------------------------------\n",
    "# แบ่ง dataset\n",
    "# -------------------------------\n",
    "move_files(images[:n_train], \"train\")\n",
    "move_files(images[n_train:n_train+n_val], \"val\")\n",
    "move_files(images[n_train+n_val:], \"test\")\n",
    "\n",
    "print(\"✅ แบ่ง dataset เสร็จแล้ว → อยู่ใน:\", output_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.206 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.201  Python-3.10.18 torch-2.0.1+cu118 CUDA:0 (NVIDIA GeForce GTX 1060, 6144MiB)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch._C' has no attribute '_has_mps'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolov8s.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# small model, VRAM 8GB ยังรองรับ\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_yaml\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m560\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# ขนาดภาพใหญ่ขึ้น\u001b[39;49;00m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# เพิ่ม batch size ให้ใช้ RAM 32GB\u001b[39;49;00m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mplate_detector\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# เพิ่มความแม่น\u001b[39;49;00m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# ใช้ GPU\u001b[39;49;00m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhalf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# FP16 ลด VRAM\u001b[39;49;00m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# ทดสอบโมเดล\u001b[39;00m\n\u001b[0;32m     34\u001b[0m results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[0;32m     35\u001b[0m     source\u001b[38;5;241m=\u001b[39mimages_dir,\n\u001b[0;32m     36\u001b[0m     save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     37\u001b[0m     conf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m\n\u001b[0;32m     38\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ultralytics\\engine\\model.py:795\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    792\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    793\u001b[0m     args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt_path\n\u001b[1;32m--> 795\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m (trainer \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_smart_load(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrainer\u001b[39m\u001b[38;5;124m\"\u001b[39m))(overrides\u001b[38;5;241m=\u001b[39margs, _callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks)\n\u001b[0;32m    796\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# manually set model only if not resuming\u001b[39;00m\n\u001b[0;32m    797\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mget_model(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39myaml)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ultralytics\\models\\yolo\\detect\\train.py:65\u001b[0m, in \u001b[0;36mDetectionTrainer.__init__\u001b[1;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, cfg\u001b[38;5;241m=\u001b[39mDEFAULT_CFG, overrides: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, _callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     57\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;124;03m    Initialize a DetectionTrainer object for training YOLO object detection model training.\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;124;03m        _callbacks (list, optional): List of callback functions to be executed during training.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_callbacks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ultralytics\\engine\\trainer.py:132\u001b[0m, in \u001b[0;36mBaseTrainer.__init__\u001b[1;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplots \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 132\u001b[0m init_seeds(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mseed \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m RANK, deterministic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdeterministic)\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# Dirs\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m=\u001b[39m get_save_dir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ultralytics\\utils\\torch_utils.py:625\u001b[0m, in \u001b[0;36minit_seeds\u001b[1;34m(seed, deterministic)\u001b[0m\n\u001b[0;32m    620\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mModelEMA\u001b[39;00m:\n\u001b[0;32m    621\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;124;03m    Updated Exponential Moving Average (EMA) implementation.\u001b[39;00m\n\u001b[0;32m    623\u001b[0m \n\u001b[0;32m    624\u001b[0m \u001b[38;5;124;03m    Keeps a moving average of everything in the model state_dict (parameters and buffers).\u001b[39;00m\n\u001b[1;32m--> 625\u001b[0m \u001b[38;5;124;03m    For EMA details see References.\u001b[39;00m\n\u001b[0;32m    626\u001b[0m \n\u001b[0;32m    627\u001b[0m \u001b[38;5;124;03m    To disable EMA set the `enabled` attribute to `False`.\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \n\u001b[0;32m    629\u001b[0m \u001b[38;5;124;03m    Attributes:\u001b[39;00m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;124;03m        ema (nn.Module): Copy of the model in evaluation mode.\u001b[39;00m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;124;03m        updates (int): Number of EMA updates.\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;124;03m        decay (function): Decay function that determines the EMA weight.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;124;03m        enabled (bool): Whether EMA is enabled.\u001b[39;00m\n\u001b[0;32m    634\u001b[0m \n\u001b[0;32m    635\u001b[0m \u001b[38;5;124;03m    References:\u001b[39;00m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;124;03m        - https://github.com/rwightman/pytorch-image-models\u001b[39;00m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;124;03m        - https://www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage\u001b[39;00m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    640\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9999\u001b[39m, tau\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m, updates\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    641\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;124;03m        Initialize EMA for 'model' with given arguments.\u001b[39;00m\n\u001b[0;32m    643\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    648\u001b[0m \u001b[38;5;124;03m            updates (int, optional): Initial number of updates.\u001b[39;00m\n\u001b[0;32m    649\u001b[0m \u001b[38;5;124;03m        \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\random.py:44\u001b[0m, in \u001b[0;36mmanual_seed\u001b[1;34m(seed)\u001b[0m\n\u001b[0;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\mps\\__init__.py:71\u001b[0m, in \u001b[0;36mmanual_seed\u001b[1;34m(seed)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sets the seed for generating random numbers.\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \n\u001b[0;32m     64\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    seed (int): The desired seed.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# the torch.mps.manual_seed() can be called from the global\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# torch.manual_seed() in torch/random.py. So we need to make\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# sure mps is available (otherwise we just return without\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# erroring out)\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_has_mps\u001b[49m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     73\u001b[0m seed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(seed)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch._C' has no attribute '_has_mps'"
     ]
    }
   ],
   "source": [
    "images_dir = \"cartest\"  \n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "data_yaml  = \"datasets/YOLO/data.yaml\"\n",
    "# -------------------------------\n",
    "\n",
    "\n",
    "# เลือกโมเดล\n",
    "model = YOLO(\"yolov8s.pt\")  # small model, VRAM 8GB ยังรองรับ\n",
    "\n",
    "# Train\n",
    "model.train(\n",
    "    data=data_yaml,\n",
    "    epochs=100,\n",
    "    imgsz=560,       # ขนาดภาพใหญ่ขึ้น\n",
    "    batch=8,        \n",
    "    name=\"plate_detector\",\n",
    "    augment=True,    # เพิ่มความแม่น\n",
    "    device=0 ,         # ใช้ GPU\n",
    "    half=True     # FP16 ลด VRAM\n",
    "    \n",
    ")\n",
    "\n",
    "# ทดสอบโมเดล\n",
    "results = model.predict(\n",
    "    source=images_dir,\n",
    "    save=True,\n",
    "    conf=0.5\n",
    ")\n",
    "print(\"✅ Prediction finished, check runs/detect/plate_detector/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:open_image_models.detection.core.yolo_v9.inference:Using ONNX Runtime with ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider'] provider(s)\n",
      "INFO:open_image_models.detection.pipeline.license_plate:Initialized LicensePlateDetector with model C:\\Users\\Know\\.cache\\open-image-models\\yolo-v9-t-384-license-plate-end2end\\yolo-v9-t-384-license-plates-end2end.onnx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ EasyOCR_ALPR loaded (GPU=True)\n",
      "*************** EP Error ***************\n",
      "EP Error E:\\_work\\1\\s\\onnxruntime\\python\\onnxruntime_pybind_state.cc:559 onnxruntime::python::RegisterTensorRTPluginsAsCustomOps Please install TensorRT libraries as mentioned in the GPU requirements page, make sure they're in the PATH or LD_LIBRARY_PATH, and that your GPU is supported.\n",
      " when using ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n",
      "Falling back to ['CPUExecutionProvider'] and retrying.\n",
      "****************************************\n",
      "✅ เริ่มระบบ (ตรวจทุก 10 วินาที). กด q เพื่อออก\n",
      "\n",
      "--- ตรวจหา plate เวลา: 2025-10-17T21:51:00.534275 ---\n",
      "  ไม่มีป้ายรถที่อ่านได้ในรอบนี้\n",
      "ออกโดยผู้ใช้\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Parking-watch simulator:\n",
    "- รันกล้องต่อเนื่อง\n",
    "- ตรวจหา plate ทุก 10 วินาที\n",
    "- ถ้าไม่มีรถ -> ไม่มีอะไรเกิดขึ้น\n",
    "- ถ้ามีทะเบียน -> เก็บเป็น target\n",
    "- ถ้าเจอทะเบียนเดิมต่อเนื่องและเวลาตั้งแต่เจอครั้งแรก >= 120s -> แคปภาพทั้งคัน + print บันทึก\n",
    "- ถ้าเจอทะเบียนใหม่ (ไม่ตรงกับ target) -> รีเซ็ต target ไปหาใหม่\n",
    "- พิมพ์สถานะทั้งหมด (no DB, no network)\n",
    "\"\"\"\n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import difflib\n",
    "from ultralytics import YOLO\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "import os\n",
    "from requests_toolbelt.multipart.encoder import MultipartEncoder\n",
    "\n",
    "def get_def_headers():\n",
    "    return {\n",
    "        \"X-API-KEY\": \"123456\"\n",
    "    }\n",
    "\n",
    "def get_base_api():\n",
    "    return 'http://ec2-54-87-52-160.compute-1.amazonaws.com'\n",
    "\n",
    "\n",
    "# Camera id use for identify location of their cameras\n",
    "# please use these id below for testing:\n",
    "# ad7de137-9287-402a-8b70-53684d96c88f: Future park, Rangsit, Thanyaburi, Prachatipat, Pathum Thani\n",
    "# 2ec15a48-c819-494c-a807-5c0f41ebaf36: BTS Asok, Klongtoey Noei, Wattana, Bangkok\n",
    "# 0e76998d-0590-4679-924a-049f92ab0b81: Lotus Laksi, Bangkhen, Anusawaree, Bangkok\n",
    "\n",
    "\n",
    "# Send Notify API\n",
    "def send_notify(license_plate: str, camera_id: str, upload_id: str):\n",
    "    notify_api = get_base_api() + \"/notify/v1/send\"\n",
    "    notify_json = {\n",
    "        'licensePlate': license_plate,\n",
    "        'cameraId': camera_id,\n",
    "        'uploadId': upload_id\n",
    "    }\n",
    "    response = requests.post(notify_api, json=notify_json, headers=get_def_headers())\n",
    "    return response.json()\n",
    "\n",
    "# Upload Image API\n",
    "def upload_image(image_path):\n",
    "    upload_api = get_base_api() + \"/media/v1/upload/image\"\n",
    "    filename = os.path.basename(image_path)\n",
    "\n",
    "    with open(image_path, 'rb') as img_file:\n",
    "        multipart_data = MultipartEncoder(\n",
    "            fields={'image': (filename, img_file, 'image/jpeg')}\n",
    "        )\n",
    "        headers = get_def_headers()\n",
    "        headers['Content-Type'] = multipart_data.content_type\n",
    "        \n",
    "        response = requests.post(upload_api, data=multipart_data, headers=headers)\n",
    "    return response.json()\n",
    "# ---------------------------- fast_alpr import ----------------------------\n",
    "try:\n",
    "    from fast_alpr.alpr import ALPR, BaseOCR, OcrResult\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"❌ fast_alpr import failed: {e}\\nInstall with: pip install fast-alpr\")\n",
    "\n",
    "# ---------------------------- จังหวัดไทย ----------------------------\n",
    "thai_provinces = [\n",
    "    \"กรุงเทพมหานคร\", \"กระบี่\", \"กาญจนบุรี\", \"กาฬสินธุ์\", \"กำแพงเพชร\",\n",
    "    \"ขอนแก่น\", \"จันทบุรี\", \"ฉะเชิงเทรา\", \"ชลบุรี\", \"ชัยนาท\",\n",
    "    \"ชัยภูมิ\", \"ชุมพร\", \"เชียงราย\", \"เชียงใหม่\", \"ตรัง\",\n",
    "    \"ตราด\", \"ตาก\", \"นครนายก\", \"นครปฐม\", \"นครพนม\",\n",
    "    \"นครราชสีมา\", \"นครศรีธรรมราช\", \"นครสวรรค์\", \"นนทบุรี\", \"นราธิวาส\",\n",
    "    \"น่าน\", \"บึงกาฬ\", \"บุรีรัมย์\", \"ปทุมธานี\", \"ประจวบคีรีขันธ์\",\n",
    "    \"ปราจีนบุรี\", \"ปัตตานี\", \"พระนครศรีอยุธยา\", \"พังงา\", \"พัทลุง\",\n",
    "    \"พิจิตร\", \"พิษณุโลก\", \"เพชรบุรี\", \"เพชรบูรณ์\", \"แพร่\",\n",
    "    \"พะเยา\", \"ภูเก็ต\", \"มหาสารคาม\", \"มุกดาหาร\", \"แม่ฮ่องสอน\",\n",
    "    \"ยะลา\", \"ร้อยเอ็ด\", \"ระนอง\", \"ระยอง\",\n",
    "    \"ราชบุรี\", \"ลพบุรี\", \"ลำปาง\", \"ลำพูน\", \"เลย\",\n",
    "    \"ศรีสะเกษ\", \"สกลนคร\", \"สงขลา\", \"สตูล\", \"สมุทรปราการ\",\n",
    "    \"สมุทรสงคราม\", \"สมุทรสาคร\", \"สระแก้ว\", \"สระบุรี\", \"สิงห์บุรี\",\n",
    "    \"สุโขทัย\", \"สุพรรณบุรี\", \"สุราษฎร์ธานี\", \"สุรินทร์\", \"หนองคาย\",\n",
    "    \"หนองบัวลำภู\", \"อ่างทอง\", \"อำนาจเจริญ\", \"อุดรธานี\", \"อุตรดิตถ์\",\n",
    "    \"อุทัยธานี\", \"อุบลราชธานี\", \"ประเทศไทย\"\n",
    "]\n",
    "\n",
    "def correct_province(text):\n",
    "    if not text:\n",
    "        return None\n",
    "    match = difflib.get_close_matches(text, thai_provinces, n=1, cutoff=0.3)\n",
    "    return match[0] if match else None\n",
    "\n",
    "# ---------------------------- OCR Engine ----------------------------\n",
    "GPU_AVAILABLE = torch.cuda.is_available()\n",
    "\n",
    "class EasyOCR_ALPR(BaseOCR):\n",
    "    def __init__(self, lang_list=['th','en'], min_conf=0.1):\n",
    "        import easyocr\n",
    "        self.reader = easyocr.Reader(lang_list, gpu=GPU_AVAILABLE)\n",
    "        self.min_conf = min_conf\n",
    "        print(f\"✅ EasyOCR_ALPR loaded (GPU={GPU_AVAILABLE})\")\n",
    "\n",
    "    def predict(self, image: np.ndarray):\n",
    "        # Enhancement simple\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape)==3 else image\n",
    "        gray = cv2.bilateralFilter(gray, 6, 45, 45)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        gray = clahe.apply(gray)\n",
    "        ocr_results = self.reader.readtext(gray)\n",
    "        results = []\n",
    "        for r in ocr_results:\n",
    "            bbox, text, conf = r if len(r)==3 else (None, r[1], 1.0)\n",
    "            if conf >= self.min_conf and text.strip():\n",
    "                results.append(OcrResult(text=text.strip(), confidence=float(conf)))\n",
    "        return results\n",
    "\n",
    "# ---------------------------- helpers (plate extraction + enhance) ----------------------------\n",
    "def correct_common_thai_ocr_errors(text):\n",
    "    corrections = {\n",
    "        \"ญณ\": \"ฌฌ\", \"ญญ\": \"ฌฌ\", \"ญ\": \"ฌ\"\n",
    "    }\n",
    "    for wrong, right in corrections.items():\n",
    "        text = text.replace(wrong, right)\n",
    "    return text\n",
    "\n",
    "def upscale_image(img, scale=3):\n",
    "    h, w = img.shape[:2]\n",
    "    return cv2.resize(img, (w*scale, h*scale), interpolation=cv2.INTER_LANCZOS4)\n",
    "\n",
    "def extract_province_from_text(text):\n",
    "    candidates = re.split(r\"[\\s\\n]+\", text)\n",
    "    for word in candidates:\n",
    "        match = difflib.get_close_matches(word, thai_provinces, n=1, cutoff=0.25)\n",
    "        if match:\n",
    "            return match[0]\n",
    "    return None\n",
    "\n",
    "def extract_thai_license_plate(text):\n",
    "    cleaned = re.sub(r\"[\\n\\r]+\", \" \", text)\n",
    "    cleaned = re.sub(r\"[^ก-ฮ0-9\\s\\-\\.]\", \"\", text)\n",
    "    cleaned = re.sub(r\"\\s+\", \" \", cleaned).strip()\n",
    "    pattern = (\n",
    "        r\"([0-9]{0,2}\\s*[ก-ฮ]{1,3}[\\s\\-\\.]*\\d{1,4})\"     # หมายเลขทะเบียน\n",
    "        r\"[\\s\\n]*\"\n",
    "        r\"(?:จังหวัด)?\\s*([ก-ฮ]{2,20})?\"                 # จังหวัด (optional)\n",
    "    )\n",
    "    matches = re.findall(pattern, cleaned)\n",
    "    results = []\n",
    "    for plate, province in matches:\n",
    "        plate = re.sub(r\"[\\s\\-\\.]\", \"\", plate)\n",
    "        province = province.strip() if province else None\n",
    "        if province:\n",
    "            best_match = difflib.get_close_matches(province, thai_provinces, n=1, cutoff=0.25)\n",
    "            province = best_match[0] if best_match else None\n",
    "        results.append({\"plate\": plate, \"province\": province})\n",
    "    return results\n",
    "\n",
    "def enhance_for_ocr(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if len(img.shape)==3 else img.copy()\n",
    "    gray = cv2.bilateralFilter(gray, 5, 80, 80)\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(5,5))\n",
    "    gray = clahe.apply(gray)\n",
    "    gray = cv2.GaussianBlur(gray, (3,3), 0)\n",
    "    gray = cv2.resize(gray, None, fx=3.5, fy=3.5, interpolation=cv2.INTER_CUBIC)\n",
    "    th = cv2.adaptiveThreshold(gray, 255,\n",
    "                               cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "                               cv2.THRESH_BINARY,\n",
    "                               blockSize=35, C=15)\n",
    "\n",
    "    # 🔹เพิ่ม sharpen เพื่อให้ขอบคมขึ้น\n",
    "    kernel_sharp = np.array([[0,-1,0],[-1,5,-1],[0,-1,0]])\n",
    "    th = cv2.filter2D(th, -1, kernel_sharp)\n",
    "\n",
    "    # ถ้าพื้นหลังกลับด้านก็กลับให้ถูก\n",
    "    if np.sum(th == 0) > np.sum(th == 255):\n",
    "        th = cv2.bitwise_not(th)\n",
    "\n",
    "    return th\n",
    "\n",
    "def safe_crop(img,x1,y1,x2,y2,pad=5):\n",
    "    h,w=img.shape[:2]\n",
    "    x1=max(0,x1-pad)\n",
    "    y1=max(0,y1-pad)\n",
    "    x2=min(w,x2+pad)\n",
    "    y2=min(h,y2+pad)\n",
    "    return img[y1:y2,x1:x2]\n",
    "\n",
    "# ---------------------------- Initialize ALPR & YOLO ----------------------------\n",
    "ocr_engine = EasyOCR_ALPR(lang_list=['th','en'])\n",
    "alpr = ALPR(ocr=ocr_engine)   # ใช้งาน fast_alpr wrapper ของคุณ\n",
    "YOLO_WEIGHTS = \"runs/detect/plate_detector/weights/best.pt\"  # เปลี่ยนให้ถูกต้อง\n",
    "model = YOLO(YOLO_WEIGHTS)\n",
    "\n",
    "# ---------------------------- Simulation / monitoring params ----------------------------\n",
    "\n",
    "source = \"demos/Easy.mp4\" # เปลี่ยนเป็นไฟล์วิดีโอ \"car001.mp4\" หรือ 0 สำหรับกล้อง\n",
    "CHECK_INTERVAL = 4.0   # วินาที — ตรวจหา plate ทุก 10 วิ\n",
    "LONG_STAY_THRESHOLD = 5.0  # วินาที — ถ้าซ้ำเกิน 2 นาที => long stay\n",
    "OUTPUT_DIR = \"output_longstay\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# tracking state (single-target logic ตามที่ขอ)\n",
    "target_plate = None            # ป้ายที่กำลังติดตาม (string)\n",
    "target_first_seen = None       # datetime ของการพบครั้งแรกสำหรับ target\n",
    "target_last_seen = None        # datetime ของการพบล่าสุด (update ทุกครั้งที่เห็น same plate)\n",
    "\n",
    "# ---------------------------- Main loop ----------------------------\n",
    "cap = cv2.VideoCapture(source)\n",
    "last_check = 0.0\n",
    "\n",
    "print(\"✅ เริ่มระบบ (ตรวจทุก 10 วินาที). กด q เพื่อออก\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"❌ ไม่สามารถอ่าน frame ได้ (end of video or camera error). หยุดการทำงาน.\")\n",
    "        break\n",
    "\n",
    "    now = time.time()\n",
    "    # แสดงเฟรมสด (ไม่บล็อก)\n",
    "    cv2.imshow(\"ALPR Live\", frame)\n",
    "    if cv2.waitKey(290) & 0xFF == ord('q'):\n",
    "        print(\"ออกโดยผู้ใช้\")\n",
    "        break\n",
    "\n",
    "    # ตรวจในช่วง interval เท่านั้น\n",
    "    if now - last_check < CHECK_INTERVAL:\n",
    "        continue\n",
    "    last_check = now\n",
    "    check_dt = datetime.now()\n",
    "    print(f\"\\n--- ตรวจหา plate เวลา: {check_dt.isoformat()} ---\")\n",
    "\n",
    "    # ใช้ YOLO detect plates (ถ้าไม่มี plate จะได้ boxes เป็น empty)\n",
    "    results = model.predict(frame, conf=0.4, verbose=False)\n",
    "    boxes = results[0].boxes.xyxy.cpu().numpy() if len(results) > 0 else []\n",
    "\n",
    "    detected_plate = None\n",
    "    detected_province = None\n",
    "\n",
    "    # หากเจอกล่องหลายกล่อง ให้พยายามอ่านทุกกล่องแล้วเลือกตัวแรกที่อ่านได้\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        h_box = y2 - y1\n",
    "        extra = int(h_box * 0.8)  # ขยายมากกว่าเดิม เพื่อให้กินส่วนจังหวัดแน่ๆ\n",
    "        y2_expanded = min(frame.shape[0], y2 + extra)\n",
    "        crop = safe_crop(frame, x1, y1, x2, y2_expanded, pad=6)\n",
    "        if crop.size == 0:\n",
    "            continue\n",
    "\n",
    "        # upscale + enhance\n",
    "        crop_up = upscale_image(crop, scale=2)\n",
    "        crop_enh = enhance_for_ocr(crop_up)\n",
    "        cv2.imshow(\"Crop for OCR\", crop_enh)\n",
    "        cv2.waitKey(1)  # 1ms แค่ให้แสดง ไม่บล็อก loop\n",
    "\n",
    "        # OCR via EasyOCR_ALPR\n",
    "        ocr_results = ocr_engine.predict(crop_enh)\n",
    "        texts = [r.text.strip() for r in ocr_results if hasattr(r, \"text\") and r.text.strip()]\n",
    "        combined_text = \" \".join(texts)\n",
    "\n",
    "        plate_results = extract_thai_license_plate(combined_text)\n",
    "        if plate_results:\n",
    "            plate_info = plate_results[0]\n",
    "            detected_plate = plate_info.get('plate')\n",
    "            detected_province = plate_info.get('province') or extract_province_from_text(combined_text)\n",
    "            print(f\"  -> อ่านทะเบียนได้: {detected_plate} {detected_province or ''}\")\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            # ถ้ายังอ่านไม่ได้ อาจลองใช้ combined_text เพื่อหา province หรือคำอื่น (ไม่จำเป็นที่นี่)\n",
    "            continue\n",
    "\n",
    "    # กรณีไม่มี plate ในรอบนี้\n",
    "    if detected_plate is None:\n",
    "        print(\"  ไม่มีป้ายรถที่อ่านได้ในรอบนี้\")\n",
    "        # ถ้าไม่มีรถ: ถ้ามี target เดิมไปเรื่อย ๆ ให้แต่ละ policy รีเซ็ตหรือเก็บ last_seen?\n",
    "        # ตาม request: เมื่อไม่มีรถก็ไม่ทำอะไร (แต่ถ้าต้องการให้ target expire ให้เพิ่มเงื่อนไข)\n",
    "        continue\n",
    "\n",
    "    # ถ้าตอนนี้ยังไม่มี target -> ตั้ง target เป็น detected_plate\n",
    "    if target_plate is None:\n",
    "        target_plate = detected_plate\n",
    "        target_first_seen = check_dt\n",
    "        target_last_seen = check_dt\n",
    "        print(f\"  ตั้ง target ใหม่: {target_plate} เวลาเริ่ม {target_first_seen.isoformat()}\")\n",
    "        continue\n",
    "\n",
    "    # ถ้ามี target อยู่แล้ว -> เปรียบเทียบกับ detected_plate\n",
    "    if detected_plate != target_plate:\n",
    "        # ถ้าไม่ตรง ให้รีเซ็ต target เป็น detected_plate ใหม่ (ตามที่ขอ)\n",
    "        print(f\"  พบทะเบียนใหม่ ({detected_plate}) แตกต่างจาก target เดิม ({target_plate}) -> รีเซ็ต target\")\n",
    "        target_plate = detected_plate\n",
    "        target_first_seen = check_dt\n",
    "        target_last_seen = check_dt\n",
    "        continue\n",
    "    else:\n",
    "        # ถ้าตรงกัน (same plate) -> update last_seen และตรวจเวลา\n",
    "        target_last_seen = check_dt\n",
    "        elapsed = (target_last_seen - target_first_seen).total_seconds()\n",
    "        print(f\"  พบ target เดิม {target_plate} อีกครั้ง (elapsed = {elapsed:.1f} s)\")\n",
    "\n",
    "        if elapsed >= LONG_STAY_THRESHOLD:\n",
    "            # ถ้าซ้ำเกิน threshold -> แคปภาพทั้งเฟรม (หรือ crop) + พิมพ์บันทึก\n",
    "            print(f\"\\n>>> LONG STAY DETECTED: {target_plate}\")\n",
    "            print(f\"    - first_seen: {target_first_seen.isoformat()}\")\n",
    "            print(f\"    - last_seen : {target_last_seen.isoformat()}\")\n",
    "            print(f\"    - elapsed   : {elapsed:.1f} seconds\")\n",
    "            print(f\"    - (ในสถานการณ์จริง จะส่ง API หรือแจ้งเตือนไปยังเพื่อนที่รับผิดชอบได้ที่นี่)\\n\")\n",
    "            cv2.imwrite(\"frame.png\", frame)\n",
    "            res = upload_image(\"frame.png\")\n",
    "            send_notify(target_plate, \"ad7de137-9287-402a-8b70-53684d96c88f\", res['uploadId'])\n",
    "\n",
    "            # หลังจากแคปและพิมพ์แล้ว ให้รีเซ็ต target เพื่อเริ่มหารอบใหม่\n",
    "            target_plate = None\n",
    "            target_first_seen = None\n",
    "            target_last_seen = None\n",
    "            # และ continue loop (จะรอ next CHECK_INTERVAL)\n",
    "            continue\n",
    "\n",
    "# end main loop\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "dl_564",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "livereveal": {
   "height": "100%",
   "margin": 0,
   "maxScale": 1,
   "minScale": 1,
   "scroll": true,
   "start_slideshow_at": "selected",
   "theme": "sky",
   "transition": "zoom",
   "width": "100%"
  },
  "toc": {
   "nav_menu": {
    "height": "369px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "457px",
    "left": "0px",
    "right": "968px",
    "top": "130px",
    "width": "214px"
   },
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
