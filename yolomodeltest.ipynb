{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import xml.etree.ElementTree as ET\n",
    "from ultralytics import YOLO\n",
    "import random\n",
    "import cv2\n",
    "import pytesseract\n",
    "import torch\n",
    "import easyocr\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import defaultdict, deque\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from requests_toolbelt.multipart.encoder import MultipartEncoder\n",
    "\n",
    "def get_def_headers():\n",
    "    return {\n",
    "        \"X-API-KEY\": \"123456\"\n",
    "    }\n",
    "\n",
    "def get_base_api():\n",
    "    return 'http://ec2-54-87-52-160.compute-1.amazonaws.com'\n",
    "\n",
    "\n",
    "# Camera id use for identify location of their cameras\n",
    "# please use these id below for testing:\n",
    "# ad7de137-9287-402a-8b70-53684d96c88f: Future park, Rangsit, Thanyaburi, Prachatipat, Pathum Thani\n",
    "# 2ec15a48-c819-494c-a807-5c0f41ebaf36: BTS Asok, Klongtoey Noei, Wattana, Bangkok\n",
    "# 0e76998d-0590-4679-924a-049f92ab0b81: Lotus Laksi, Bangkhen, Anusawaree, Bangkok\n",
    "\n",
    "\n",
    "# Send Notify API\n",
    "def send_notify(license_plate: str, camera_id: str, upload_id: str):\n",
    "    notify_api = get_base_api() + \"/notify/v1/send\"\n",
    "    notify_json = {\n",
    "        'licensePlate': license_plate,\n",
    "        'cameraId': camera_id,\n",
    "        'uploadId': upload_id\n",
    "    }\n",
    "    response = requests.post(notify_api, json=notify_json, headers=get_def_headers())\n",
    "    return response.json()\n",
    "\n",
    "# Upload Image API\n",
    "def upload_image(image_path):\n",
    "    upload_api = get_base_api() + \"/media/v1/upload/image\"\n",
    "    filename = os.path.basename(image_path)\n",
    "\n",
    "    with open(image_path, 'rb') as img_file:\n",
    "        multipart_data = MultipartEncoder(\n",
    "            fields={'image': (filename, img_file, 'image/jpeg')}\n",
    "        )\n",
    "        headers = get_def_headers()\n",
    "        headers['Content-Type'] = multipart_data.content_type\n",
    "        \n",
    "        response = requests.post(upload_api, data=multipart_data, headers=headers)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Send Notify without Image response: {'notifyId': 'c2a1390c-45e3-414b-a6fb-a530a0409b6d', 'status': 'PENDING'}\n"
     ]
    }
   ],
   "source": [
    "# Example Send Notify without Image\n",
    "no_img_license_plate = \"7‡∏Å‡∏ç 3603 ‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£\"\n",
    "no_img_camera = \"ad7de137-9287-402a-8b70-53684d96c88f\"\n",
    "response = send_notify(no_img_license_plate, no_img_camera, '')\n",
    "print(\"Send Notify without Image response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Send Upload response: {'uploadId': '71bfe9c0-204f-4011-a1ed-6e81be8f386f', 'fileId': '5ff3a40a-513d-47c2-9d60-d0afacbf0e6f', 'filePath': '71bfe9c0-204f-4011-a1ed-6e81be8f386f/5ff3a40a-513d-47c2-9d60-d0afacbf0e6f.jpg', 'contentType': 'jpg', 'status': 'SUCCESS'}\n",
      "Send Notify with Image response: {'notifyId': 'c2a1390c-45e3-414b-a6fb-a530a0409b6d', 'status': 'PENDING'}\n"
     ]
    }
   ],
   "source": [
    "# Example Send Upload Image\n",
    "img_path = './runs/detect/predict4/car02.jpg'\n",
    "upload_response = upload_image(img_path)\n",
    "print(\"Send Upload response:\", upload_response)\n",
    "\n",
    "# Example Send Notify with Image\n",
    "img_license_plate = '9‡∏Å‡∏î 1881 ‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£'\n",
    "img_camera = 'ad7de137-9287-402a-8b70-53684d96c88f'\n",
    "img_upload = upload_response['uploadId']\n",
    "notify_response = send_notify(img_license_plate, img_camera, img_upload)\n",
    "print(\"Send Notify with Image response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡∏û‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î 1402 ‡∏£‡∏π‡∏õ ‚Üí Train=981, Val=280, Test=141\n",
      "‚úÖ ‡πÅ‡∏ö‡πà‡∏á dataset ‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß ‚Üí ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô: datasets/YOLO\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ö‡πà‡∏á dataset ‡πÄ‡∏õ‡πá‡∏ô train/val/test\n",
    "# -------------------------------\n",
    "images_dir = \"data/images_all\"      # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏Å‡πá‡∏ö‡∏†‡∏≤‡∏û‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡πÄ‡∏ä‡πà‡∏ô D:\\yolo\\Project_2\\data\\images_all)\n",
    "labels_dir = \"data/labels_all\"      # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏Å‡πá‡∏ö labels ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡πÄ‡∏ä‡πà‡∏ô D:\\yolo\\Project_2\\data\\labels_all)\n",
    "\n",
    "output_base = \"datasets/YOLO\"       # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö train/val/test\n",
    "split_ratio = (0.7, 0.2, 0.1)       # train, val, test\n",
    "\n",
    "# -------------------------------\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå input ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ\n",
    "# -------------------------------\n",
    "if not os.path.exists(images_dir):\n",
    "    os.makedirs(images_dir)\n",
    "    print(f\"‚ö†Ô∏è ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå '{images_dir}' ‡πÅ‡∏•‡πâ‡∏ß (‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤) ‚Üí ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏™‡πà‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û‡∏Å‡πà‡∏≠‡∏ô\")\n",
    "\n",
    "if not os.path.exists(labels_dir):\n",
    "    os.makedirs(labels_dir)\n",
    "    print(f\"‚ö†Ô∏è ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå '{labels_dir}' ‡πÅ‡∏•‡πâ‡∏ß (‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤) ‚Üí ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏™‡πà‡πÑ‡∏ü‡∏•‡πå labels ‡∏Å‡πà‡∏≠‡∏ô\")\n",
    "\n",
    "# -------------------------------\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå output (images + labels + split)\n",
    "# -------------------------------\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    os.makedirs(os.path.join(output_base, \"images\", split), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_base, \"labels\", split), exist_ok=True)\n",
    "\n",
    "# -------------------------------\n",
    "# ‡∏£‡∏ß‡∏°‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û\n",
    "# -------------------------------\n",
    "images = [f for f in os.listdir(images_dir) if f.lower().endswith((\".jpg\", \".png\"))]\n",
    "\n",
    "if not images:\n",
    "    print(f\"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û‡πÉ‡∏ô '{images_dir}' ‚Üí ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏™‡πà‡∏†‡∏≤‡∏û‡∏Å‡πà‡∏≠‡∏ô\")\n",
    "    exit()\n",
    "\n",
    "import random\n",
    "random.shuffle(images)\n",
    "\n",
    "n_total = len(images)\n",
    "n_train = int(split_ratio[0] * n_total)\n",
    "n_val = int(split_ratio[1] * n_total)\n",
    "n_test = n_total - n_train - n_val\n",
    "\n",
    "print(f\"‡∏û‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {n_total} ‡∏£‡∏π‡∏õ ‚Üí Train={n_train}, Val={n_val}, Test={n_test}\")\n",
    "\n",
    "# -------------------------------\n",
    "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå\n",
    "# -------------------------------\n",
    "import shutil\n",
    "def move_files(file_list, split):\n",
    "    for img_file in file_list:\n",
    "        src_img = os.path.join(images_dir, img_file)\n",
    "        dst_img = os.path.join(output_base, \"images\", split, img_file)\n",
    "\n",
    "        # path ‡∏Ç‡∏≠‡∏á label (‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡πÅ‡∏ï‡πà .txt)\n",
    "        label_file = os.path.splitext(img_file)[0] + \".txt\"\n",
    "        src_lbl = os.path.join(labels_dir, label_file)\n",
    "        dst_lbl = os.path.join(output_base, \"labels\", split, label_file)\n",
    "\n",
    "        # copy ‡∏†‡∏≤‡∏û\n",
    "        shutil.copy(src_img, dst_img)\n",
    "\n",
    "        # copy label ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ\n",
    "        if os.path.exists(src_lbl):\n",
    "            shutil.copy(src_lbl, dst_lbl)\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ label ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {img_file}\")\n",
    "\n",
    "# -------------------------------\n",
    "# ‡πÅ‡∏ö‡πà‡∏á dataset\n",
    "# -------------------------------\n",
    "move_files(images[:n_train], \"train\")\n",
    "move_files(images[n_train:n_train+n_val], \"val\")\n",
    "move_files(images[n_train+n_val:], \"test\")\n",
    "\n",
    "print(\"‚úÖ ‡πÅ‡∏ö‡πà‡∏á dataset ‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß ‚Üí ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô:\", output_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.206 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.201  Python-3.10.18 torch-2.0.1+cu118 CUDA:0 (NVIDIA GeForce GTX 1060, 6144MiB)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch._C' has no attribute '_has_mps'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolov8s.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# small model, VRAM 8GB ‡∏¢‡∏±‡∏á‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_yaml\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m560\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# ‡∏Ç‡∏ô‡∏≤‡∏î‡∏†‡∏≤‡∏û‡πÉ‡∏´‡∏ç‡πà‡∏Ç‡∏∂‡πâ‡∏ô\u001b[39;49;00m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# ‡πÄ‡∏û‡∏¥‡πà‡∏° batch size ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ RAM 32GB\u001b[39;49;00m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mplate_detector\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô\u001b[39;49;00m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# ‡πÉ‡∏ä‡πâ GPU\u001b[39;49;00m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhalf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# FP16 ‡∏•‡∏î VRAM\u001b[39;49;00m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•\u001b[39;00m\n\u001b[0;32m     34\u001b[0m results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[0;32m     35\u001b[0m     source\u001b[38;5;241m=\u001b[39mimages_dir,\n\u001b[0;32m     36\u001b[0m     save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     37\u001b[0m     conf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m\n\u001b[0;32m     38\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ultralytics\\engine\\model.py:795\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    792\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    793\u001b[0m     args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt_path\n\u001b[1;32m--> 795\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m (trainer \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_smart_load(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrainer\u001b[39m\u001b[38;5;124m\"\u001b[39m))(overrides\u001b[38;5;241m=\u001b[39margs, _callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks)\n\u001b[0;32m    796\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# manually set model only if not resuming\u001b[39;00m\n\u001b[0;32m    797\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mget_model(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39myaml)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ultralytics\\models\\yolo\\detect\\train.py:65\u001b[0m, in \u001b[0;36mDetectionTrainer.__init__\u001b[1;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, cfg\u001b[38;5;241m=\u001b[39mDEFAULT_CFG, overrides: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, _callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     57\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;124;03m    Initialize a DetectionTrainer object for training YOLO object detection model training.\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;124;03m        _callbacks (list, optional): List of callback functions to be executed during training.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_callbacks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ultralytics\\engine\\trainer.py:132\u001b[0m, in \u001b[0;36mBaseTrainer.__init__\u001b[1;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplots \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 132\u001b[0m init_seeds(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mseed \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m RANK, deterministic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdeterministic)\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# Dirs\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m=\u001b[39m get_save_dir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\ultralytics\\utils\\torch_utils.py:625\u001b[0m, in \u001b[0;36minit_seeds\u001b[1;34m(seed, deterministic)\u001b[0m\n\u001b[0;32m    620\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mModelEMA\u001b[39;00m:\n\u001b[0;32m    621\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;124;03m    Updated Exponential Moving Average (EMA) implementation.\u001b[39;00m\n\u001b[0;32m    623\u001b[0m \n\u001b[0;32m    624\u001b[0m \u001b[38;5;124;03m    Keeps a moving average of everything in the model state_dict (parameters and buffers).\u001b[39;00m\n\u001b[1;32m--> 625\u001b[0m \u001b[38;5;124;03m    For EMA details see References.\u001b[39;00m\n\u001b[0;32m    626\u001b[0m \n\u001b[0;32m    627\u001b[0m \u001b[38;5;124;03m    To disable EMA set the `enabled` attribute to `False`.\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \n\u001b[0;32m    629\u001b[0m \u001b[38;5;124;03m    Attributes:\u001b[39;00m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;124;03m        ema (nn.Module): Copy of the model in evaluation mode.\u001b[39;00m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;124;03m        updates (int): Number of EMA updates.\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;124;03m        decay (function): Decay function that determines the EMA weight.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;124;03m        enabled (bool): Whether EMA is enabled.\u001b[39;00m\n\u001b[0;32m    634\u001b[0m \n\u001b[0;32m    635\u001b[0m \u001b[38;5;124;03m    References:\u001b[39;00m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;124;03m        - https://github.com/rwightman/pytorch-image-models\u001b[39;00m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;124;03m        - https://www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage\u001b[39;00m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    640\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9999\u001b[39m, tau\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m, updates\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    641\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;124;03m        Initialize EMA for 'model' with given arguments.\u001b[39;00m\n\u001b[0;32m    643\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    648\u001b[0m \u001b[38;5;124;03m            updates (int, optional): Initial number of updates.\u001b[39;00m\n\u001b[0;32m    649\u001b[0m \u001b[38;5;124;03m        \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\random.py:44\u001b[0m, in \u001b[0;36mmanual_seed\u001b[1;34m(seed)\u001b[0m\n\u001b[0;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\mps\\__init__.py:71\u001b[0m, in \u001b[0;36mmanual_seed\u001b[1;34m(seed)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sets the seed for generating random numbers.\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \n\u001b[0;32m     64\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    seed (int): The desired seed.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# the torch.mps.manual_seed() can be called from the global\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# torch.manual_seed() in torch/random.py. So we need to make\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# sure mps is available (otherwise we just return without\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# erroring out)\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_has_mps\u001b[49m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     73\u001b[0m seed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(seed)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch._C' has no attribute '_has_mps'"
     ]
    }
   ],
   "source": [
    "images_dir = \"cartest\"  \n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "data_yaml  = \"datasets/YOLO/data.yaml\"\n",
    "# -------------------------------\n",
    "\n",
    "\n",
    "# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
    "model = YOLO(\"yolov8s.pt\")  # small model, VRAM 8GB ‡∏¢‡∏±‡∏á‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö\n",
    "\n",
    "# Train\n",
    "model.train(\n",
    "    data=data_yaml,\n",
    "    epochs=100,\n",
    "    imgsz=560,       # ‡∏Ç‡∏ô‡∏≤‡∏î‡∏†‡∏≤‡∏û‡πÉ‡∏´‡∏ç‡πà‡∏Ç‡∏∂‡πâ‡∏ô\n",
    "    batch=8,        \n",
    "    name=\"plate_detector\",\n",
    "    augment=True,    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô\n",
    "    device=0 ,         # ‡πÉ‡∏ä‡πâ GPU\n",
    "    half=True     # FP16 ‡∏•‡∏î VRAM\n",
    "    \n",
    ")\n",
    "\n",
    "# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
    "results = model.predict(\n",
    "    source=images_dir,\n",
    "    save=True,\n",
    "    conf=0.5\n",
    ")\n",
    "print(\"‚úÖ Prediction finished, check runs/detect/plate_detector/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:open_image_models.detection.core.yolo_v9.inference:Using ONNX Runtime with ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider'] provider(s)\n",
      "INFO:open_image_models.detection.pipeline.license_plate:Initialized LicensePlateDetector with model C:\\Users\\Know\\.cache\\open-image-models\\yolo-v9-t-384-license-plate-end2end\\yolo-v9-t-384-license-plates-end2end.onnx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ EasyOCR_ALPR loaded (GPU=True)\n",
      "*************** EP Error ***************\n",
      "EP Error E:\\_work\\1\\s\\onnxruntime\\python\\onnxruntime_pybind_state.cc:559 onnxruntime::python::RegisterTensorRTPluginsAsCustomOps Please install TensorRT libraries as mentioned in the GPU requirements page, make sure they're in the PATH or LD_LIBRARY_PATH, and that your GPU is supported.\n",
      " when using ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n",
      "Falling back to ['CPUExecutionProvider'] and retrying.\n",
      "****************************************\n",
      "‚úÖ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏£‡∏∞‡∏ö‡∏ö (‡∏ï‡∏£‡∏ß‡∏à‡∏ó‡∏∏‡∏Å 10 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ). ‡∏Å‡∏î q ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å\n",
      "\n",
      "--- ‡∏ï‡∏£‡∏ß‡∏à‡∏´‡∏≤ plate ‡πÄ‡∏ß‡∏•‡∏≤: 2025-10-17T21:51:00.534275 ---\n",
      "  ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡πâ‡∏≤‡∏¢‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏£‡∏≠‡∏ö‡∏ô‡∏µ‡πâ\n",
      "‡∏≠‡∏≠‡∏Å‡πÇ‡∏î‡∏¢‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Parking-watch simulator:\n",
    "- ‡∏£‡∏±‡∏ô‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á\n",
    "- ‡∏ï‡∏£‡∏ß‡∏à‡∏´‡∏≤ plate ‡∏ó‡∏∏‡∏Å 10 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "- ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏ñ -> ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô\n",
    "- ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô -> ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏õ‡πá‡∏ô target\n",
    "- ‡∏ñ‡πâ‡∏≤‡πÄ‡∏à‡∏≠‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡πÄ‡∏î‡∏¥‡∏°‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏ß‡∏•‡∏≤‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡πÄ‡∏à‡∏≠‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å >= 120s -> ‡πÅ‡∏Ñ‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏±‡πâ‡∏á‡∏Ñ‡∏±‡∏ô + print ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å\n",
    "- ‡∏ñ‡πâ‡∏≤‡πÄ‡∏à‡∏≠‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡πÉ‡∏´‡∏°‡πà (‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö target) -> ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï target ‡πÑ‡∏õ‡∏´‡∏≤‡πÉ‡∏´‡∏°‡πà\n",
    "- ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (no DB, no network)\n",
    "\"\"\"\n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import difflib\n",
    "from ultralytics import YOLO\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "import os\n",
    "from requests_toolbelt.multipart.encoder import MultipartEncoder\n",
    "\n",
    "def get_def_headers():\n",
    "    return {\n",
    "        \"X-API-KEY\": \"123456\"\n",
    "    }\n",
    "\n",
    "def get_base_api():\n",
    "    return 'http://ec2-54-87-52-160.compute-1.amazonaws.com'\n",
    "\n",
    "\n",
    "# Camera id use for identify location of their cameras\n",
    "# please use these id below for testing:\n",
    "# ad7de137-9287-402a-8b70-53684d96c88f: Future park, Rangsit, Thanyaburi, Prachatipat, Pathum Thani\n",
    "# 2ec15a48-c819-494c-a807-5c0f41ebaf36: BTS Asok, Klongtoey Noei, Wattana, Bangkok\n",
    "# 0e76998d-0590-4679-924a-049f92ab0b81: Lotus Laksi, Bangkhen, Anusawaree, Bangkok\n",
    "\n",
    "\n",
    "# Send Notify API\n",
    "def send_notify(license_plate: str, camera_id: str, upload_id: str):\n",
    "    notify_api = get_base_api() + \"/notify/v1/send\"\n",
    "    notify_json = {\n",
    "        'licensePlate': license_plate,\n",
    "        'cameraId': camera_id,\n",
    "        'uploadId': upload_id\n",
    "    }\n",
    "    response = requests.post(notify_api, json=notify_json, headers=get_def_headers())\n",
    "    return response.json()\n",
    "\n",
    "# Upload Image API\n",
    "def upload_image(image_path):\n",
    "    upload_api = get_base_api() + \"/media/v1/upload/image\"\n",
    "    filename = os.path.basename(image_path)\n",
    "\n",
    "    with open(image_path, 'rb') as img_file:\n",
    "        multipart_data = MultipartEncoder(\n",
    "            fields={'image': (filename, img_file, 'image/jpeg')}\n",
    "        )\n",
    "        headers = get_def_headers()\n",
    "        headers['Content-Type'] = multipart_data.content_type\n",
    "        \n",
    "        response = requests.post(upload_api, data=multipart_data, headers=headers)\n",
    "    return response.json()\n",
    "# ---------------------------- fast_alpr import ----------------------------\n",
    "try:\n",
    "    from fast_alpr.alpr import ALPR, BaseOCR, OcrResult\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"‚ùå fast_alpr import failed: {e}\\nInstall with: pip install fast-alpr\")\n",
    "\n",
    "# ---------------------------- ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÑ‡∏ó‡∏¢ ----------------------------\n",
    "thai_provinces = [\n",
    "    \"‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£\", \"‡∏Å‡∏£‡∏∞‡∏ö‡∏µ‡πà\", \"‡∏Å‡∏≤‡∏ç‡∏à‡∏ô‡∏ö‡∏∏‡∏£‡∏µ\", \"‡∏Å‡∏≤‡∏¨‡∏™‡∏¥‡∏ô‡∏ò‡∏∏‡πå\", \"‡∏Å‡∏≥‡πÅ‡∏û‡∏á‡πÄ‡∏û‡∏ä‡∏£\",\n",
    "    \"‡∏Ç‡∏≠‡∏ô‡πÅ‡∏Å‡πà‡∏ô\", \"‡∏à‡∏±‡∏ô‡∏ó‡∏ö‡∏∏‡∏£‡∏µ\", \"‡∏â‡∏∞‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏ó‡∏£‡∏≤\", \"‡∏ä‡∏•‡∏ö‡∏∏‡∏£‡∏µ\", \"‡∏ä‡∏±‡∏¢‡∏ô‡∏≤‡∏ó\",\n",
    "    \"‡∏ä‡∏±‡∏¢‡∏†‡∏π‡∏°‡∏¥\", \"‡∏ä‡∏∏‡∏°‡∏û‡∏£\", \"‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡∏£‡∏≤‡∏¢\", \"‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà\", \"‡∏ï‡∏£‡∏±‡∏á\",\n",
    "    \"‡∏ï‡∏£‡∏≤‡∏î\", \"‡∏ï‡∏≤‡∏Å\", \"‡∏ô‡∏Ñ‡∏£‡∏ô‡∏≤‡∏¢‡∏Å\", \"‡∏ô‡∏Ñ‡∏£‡∏õ‡∏ê‡∏°\", \"‡∏ô‡∏Ñ‡∏£‡∏û‡∏ô‡∏°\",\n",
    "    \"‡∏ô‡∏Ñ‡∏£‡∏£‡∏≤‡∏ä‡∏™‡∏µ‡∏°‡∏≤\", \"‡∏ô‡∏Ñ‡∏£‡∏®‡∏£‡∏µ‡∏ò‡∏£‡∏£‡∏°‡∏£‡∏≤‡∏ä\", \"‡∏ô‡∏Ñ‡∏£‡∏™‡∏ß‡∏£‡∏£‡∏Ñ‡πå\", \"‡∏ô‡∏ô‡∏ó‡∏ö‡∏∏‡∏£‡∏µ\", \"‡∏ô‡∏£‡∏≤‡∏ò‡∏¥‡∏ß‡∏≤‡∏™\",\n",
    "    \"‡∏ô‡πà‡∏≤‡∏ô\", \"‡∏ö‡∏∂‡∏á‡∏Å‡∏≤‡∏¨\", \"‡∏ö‡∏∏‡∏£‡∏µ‡∏£‡∏±‡∏°‡∏¢‡πå\", \"‡∏õ‡∏ó‡∏∏‡∏°‡∏ò‡∏≤‡∏ô‡∏µ\", \"‡∏õ‡∏£‡∏∞‡∏à‡∏ß‡∏ö‡∏Ñ‡∏µ‡∏£‡∏µ‡∏Ç‡∏±‡∏ô‡∏ò‡πå\",\n",
    "    \"‡∏õ‡∏£‡∏≤‡∏à‡∏µ‡∏ô‡∏ö‡∏∏‡∏£‡∏µ\", \"‡∏õ‡∏±‡∏ï‡∏ï‡∏≤‡∏ô‡∏µ\", \"‡∏û‡∏£‡∏∞‡∏ô‡∏Ñ‡∏£‡∏®‡∏£‡∏µ‡∏≠‡∏¢‡∏∏‡∏ò‡∏¢‡∏≤\", \"‡∏û‡∏±‡∏á‡∏á‡∏≤\", \"‡∏û‡∏±‡∏ó‡∏•‡∏∏‡∏á\",\n",
    "    \"‡∏û‡∏¥‡∏à‡∏¥‡∏ï‡∏£\", \"‡∏û‡∏¥‡∏©‡∏ì‡∏∏‡πÇ‡∏•‡∏Å\", \"‡πÄ‡∏û‡∏ä‡∏£‡∏ö‡∏∏‡∏£‡∏µ\", \"‡πÄ‡∏û‡∏ä‡∏£‡∏ö‡∏π‡∏£‡∏ì‡πå\", \"‡πÅ‡∏û‡∏£‡πà\",\n",
    "    \"‡∏û‡∏∞‡πÄ‡∏¢‡∏≤\", \"‡∏†‡∏π‡πÄ‡∏Å‡πá‡∏ï\", \"‡∏°‡∏´‡∏≤‡∏™‡∏≤‡∏£‡∏Ñ‡∏≤‡∏°\", \"‡∏°‡∏∏‡∏Å‡∏î‡∏≤‡∏´‡∏≤‡∏£\", \"‡πÅ‡∏°‡πà‡∏Æ‡πà‡∏≠‡∏á‡∏™‡∏≠‡∏ô\",\n",
    "    \"‡∏¢‡∏∞‡∏•‡∏≤\", \"‡∏£‡πâ‡∏≠‡∏¢‡πÄ‡∏≠‡πá‡∏î\", \"‡∏£‡∏∞‡∏ô‡∏≠‡∏á\", \"‡∏£‡∏∞‡∏¢‡∏≠‡∏á\",\n",
    "    \"‡∏£‡∏≤‡∏ä‡∏ö‡∏∏‡∏£‡∏µ\", \"‡∏•‡∏û‡∏ö‡∏∏‡∏£‡∏µ\", \"‡∏•‡∏≥‡∏õ‡∏≤‡∏á\", \"‡∏•‡∏≥‡∏û‡∏π‡∏ô\", \"‡πÄ‡∏•‡∏¢\",\n",
    "    \"‡∏®‡∏£‡∏µ‡∏™‡∏∞‡πÄ‡∏Å‡∏©\", \"‡∏™‡∏Å‡∏•‡∏ô‡∏Ñ‡∏£\", \"‡∏™‡∏á‡∏Ç‡∏•‡∏≤\", \"‡∏™‡∏ï‡∏π‡∏•\", \"‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏õ‡∏£‡∏≤‡∏Å‡∏≤‡∏£\",\n",
    "    \"‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏™‡∏á‡∏Ñ‡∏£‡∏≤‡∏°\", \"‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏™‡∏≤‡∏Ñ‡∏£\", \"‡∏™‡∏£‡∏∞‡πÅ‡∏Å‡πâ‡∏ß\", \"‡∏™‡∏£‡∏∞‡∏ö‡∏∏‡∏£‡∏µ\", \"‡∏™‡∏¥‡∏á‡∏´‡πå‡∏ö‡∏∏‡∏£‡∏µ\",\n",
    "    \"‡∏™‡∏∏‡πÇ‡∏Ç‡∏ó‡∏±‡∏¢\", \"‡∏™‡∏∏‡∏û‡∏£‡∏£‡∏ì‡∏ö‡∏∏‡∏£‡∏µ\", \"‡∏™‡∏∏‡∏£‡∏≤‡∏©‡∏é‡∏£‡πå‡∏ò‡∏≤‡∏ô‡∏µ\", \"‡∏™‡∏∏‡∏£‡∏¥‡∏ô‡∏ó‡∏£‡πå\", \"‡∏´‡∏ô‡∏≠‡∏á‡∏Ñ‡∏≤‡∏¢\",\n",
    "    \"‡∏´‡∏ô‡∏≠‡∏á‡∏ö‡∏±‡∏ß‡∏•‡∏≥‡∏†‡∏π\", \"‡∏≠‡πà‡∏≤‡∏á‡∏ó‡∏≠‡∏á\", \"‡∏≠‡∏≥‡∏ô‡∏≤‡∏à‡πÄ‡∏à‡∏£‡∏¥‡∏ç\", \"‡∏≠‡∏∏‡∏î‡∏£‡∏ò‡∏≤‡∏ô‡∏µ\", \"‡∏≠‡∏∏‡∏ï‡∏£‡∏î‡∏¥‡∏ï‡∏ñ‡πå\",\n",
    "    \"‡∏≠‡∏∏‡∏ó‡∏±‡∏¢‡∏ò‡∏≤‡∏ô‡∏µ\", \"‡∏≠‡∏∏‡∏ö‡∏•‡∏£‡∏≤‡∏ä‡∏ò‡∏≤‡∏ô‡∏µ\", \"‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢\"\n",
    "]\n",
    "\n",
    "def correct_province(text):\n",
    "    if not text:\n",
    "        return None\n",
    "    match = difflib.get_close_matches(text, thai_provinces, n=1, cutoff=0.3)\n",
    "    return match[0] if match else None\n",
    "\n",
    "# ---------------------------- OCR Engine ----------------------------\n",
    "GPU_AVAILABLE = torch.cuda.is_available()\n",
    "\n",
    "class EasyOCR_ALPR(BaseOCR):\n",
    "    def __init__(self, lang_list=['th','en'], min_conf=0.1):\n",
    "        import easyocr\n",
    "        self.reader = easyocr.Reader(lang_list, gpu=GPU_AVAILABLE)\n",
    "        self.min_conf = min_conf\n",
    "        print(f\"‚úÖ EasyOCR_ALPR loaded (GPU={GPU_AVAILABLE})\")\n",
    "\n",
    "    def predict(self, image: np.ndarray):\n",
    "        # Enhancement simple\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape)==3 else image\n",
    "        gray = cv2.bilateralFilter(gray, 6, 45, 45)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        gray = clahe.apply(gray)\n",
    "        ocr_results = self.reader.readtext(gray)\n",
    "        results = []\n",
    "        for r in ocr_results:\n",
    "            bbox, text, conf = r if len(r)==3 else (None, r[1], 1.0)\n",
    "            if conf >= self.min_conf and text.strip():\n",
    "                results.append(OcrResult(text=text.strip(), confidence=float(conf)))\n",
    "        return results\n",
    "\n",
    "# ---------------------------- helpers (plate extraction + enhance) ----------------------------\n",
    "def correct_common_thai_ocr_errors(text):\n",
    "    corrections = {\n",
    "        \"‡∏ç‡∏ì\": \"‡∏å‡∏å\", \"‡∏ç‡∏ç\": \"‡∏å‡∏å\", \"‡∏ç\": \"‡∏å\"\n",
    "    }\n",
    "    for wrong, right in corrections.items():\n",
    "        text = text.replace(wrong, right)\n",
    "    return text\n",
    "\n",
    "def upscale_image(img, scale=3):\n",
    "    h, w = img.shape[:2]\n",
    "    return cv2.resize(img, (w*scale, h*scale), interpolation=cv2.INTER_LANCZOS4)\n",
    "\n",
    "def extract_province_from_text(text):\n",
    "    candidates = re.split(r\"[\\s\\n]+\", text)\n",
    "    for word in candidates:\n",
    "        match = difflib.get_close_matches(word, thai_provinces, n=1, cutoff=0.25)\n",
    "        if match:\n",
    "            return match[0]\n",
    "    return None\n",
    "\n",
    "def extract_thai_license_plate(text):\n",
    "    cleaned = re.sub(r\"[\\n\\r]+\", \" \", text)\n",
    "    cleaned = re.sub(r\"[^‡∏Å-‡∏Æ0-9\\s\\-\\.]\", \"\", text)\n",
    "    cleaned = re.sub(r\"\\s+\", \" \", cleaned).strip()\n",
    "    pattern = (\n",
    "        r\"([0-9]{0,2}\\s*[‡∏Å-‡∏Æ]{1,3}[\\s\\-\\.]*\\d{1,4})\"     # ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô\n",
    "        r\"[\\s\\n]*\"\n",
    "        r\"(?:‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î)?\\s*([‡∏Å-‡∏Æ]{2,20})?\"                 # ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î (optional)\n",
    "    )\n",
    "    matches = re.findall(pattern, cleaned)\n",
    "    results = []\n",
    "    for plate, province in matches:\n",
    "        plate = re.sub(r\"[\\s\\-\\.]\", \"\", plate)\n",
    "        province = province.strip() if province else None\n",
    "        if province:\n",
    "            best_match = difflib.get_close_matches(province, thai_provinces, n=1, cutoff=0.25)\n",
    "            province = best_match[0] if best_match else None\n",
    "        results.append({\"plate\": plate, \"province\": province})\n",
    "    return results\n",
    "\n",
    "def enhance_for_ocr(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if len(img.shape)==3 else img.copy()\n",
    "    gray = cv2.bilateralFilter(gray, 5, 80, 80)\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(5,5))\n",
    "    gray = clahe.apply(gray)\n",
    "    gray = cv2.GaussianBlur(gray, (3,3), 0)\n",
    "    gray = cv2.resize(gray, None, fx=3.5, fy=3.5, interpolation=cv2.INTER_CUBIC)\n",
    "    th = cv2.adaptiveThreshold(gray, 255,\n",
    "                               cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "                               cv2.THRESH_BINARY,\n",
    "                               blockSize=35, C=15)\n",
    "\n",
    "    # üîπ‡πÄ‡∏û‡∏¥‡πà‡∏° sharpen ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏°‡∏Ç‡∏∂‡πâ‡∏ô\n",
    "    kernel_sharp = np.array([[0,-1,0],[-1,5,-1],[0,-1,0]])\n",
    "    th = cv2.filter2D(th, -1, kernel_sharp)\n",
    "\n",
    "    # ‡∏ñ‡πâ‡∏≤‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏•‡∏±‡∏ö‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡πá‡∏Å‡∏•‡∏±‡∏ö‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å\n",
    "    if np.sum(th == 0) > np.sum(th == 255):\n",
    "        th = cv2.bitwise_not(th)\n",
    "\n",
    "    return th\n",
    "\n",
    "def safe_crop(img,x1,y1,x2,y2,pad=5):\n",
    "    h,w=img.shape[:2]\n",
    "    x1=max(0,x1-pad)\n",
    "    y1=max(0,y1-pad)\n",
    "    x2=min(w,x2+pad)\n",
    "    y2=min(h,y2+pad)\n",
    "    return img[y1:y2,x1:x2]\n",
    "\n",
    "# ---------------------------- Initialize ALPR & YOLO ----------------------------\n",
    "ocr_engine = EasyOCR_ALPR(lang_list=['th','en'])\n",
    "alpr = ALPR(ocr=ocr_engine)   # ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô fast_alpr wrapper ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì\n",
    "YOLO_WEIGHTS = \"runs/detect/plate_detector/weights/best.pt\"  # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á\n",
    "model = YOLO(YOLO_WEIGHTS)\n",
    "\n",
    "# ---------------------------- Simulation / monitoring params ----------------------------\n",
    "\n",
    "source = \"demos/Easy.mp4\" # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠ \"car001.mp4\" ‡∏´‡∏£‡∏∑‡∏≠ 0 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏•‡πâ‡∏≠‡∏á\n",
    "CHECK_INTERVAL = 4.0   # ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ ‚Äî ‡∏ï‡∏£‡∏ß‡∏à‡∏´‡∏≤ plate ‡∏ó‡∏∏‡∏Å 10 ‡∏ß‡∏¥\n",
    "LONG_STAY_THRESHOLD = 5.0  # ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ ‚Äî ‡∏ñ‡πâ‡∏≤‡∏ã‡πâ‡∏≥‡πÄ‡∏Å‡∏¥‡∏ô 2 ‡∏ô‡∏≤‡∏ó‡∏µ => long stay\n",
    "OUTPUT_DIR = \"output_longstay\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# tracking state (single-target logic ‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏Ç‡∏≠)\n",
    "target_plate = None            # ‡∏õ‡πâ‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏° (string)\n",
    "target_first_seen = None       # datetime ‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏û‡∏ö‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö target\n",
    "target_last_seen = None        # datetime ‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏û‡∏ö‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (update ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏´‡πá‡∏ô same plate)\n",
    "\n",
    "# ---------------------------- Main loop ----------------------------\n",
    "cap = cv2.VideoCapture(source)\n",
    "last_check = 0.0\n",
    "\n",
    "print(\"‚úÖ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏£‡∏∞‡∏ö‡∏ö (‡∏ï‡∏£‡∏ß‡∏à‡∏ó‡∏∏‡∏Å 10 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ). ‡∏Å‡∏î q ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô frame ‡πÑ‡∏î‡πâ (end of video or camera error). ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô.\")\n",
    "        break\n",
    "\n",
    "    now = time.time()\n",
    "    # ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏ü‡∏£‡∏°‡∏™‡∏î (‡πÑ‡∏°‡πà‡∏ö‡∏•‡πá‡∏≠‡∏Å)\n",
    "    cv2.imshow(\"ALPR Live\", frame)\n",
    "    if cv2.waitKey(290) & 0xFF == ord('q'):\n",
    "        print(\"‡∏≠‡∏≠‡∏Å‡πÇ‡∏î‡∏¢‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ\")\n",
    "        break\n",
    "\n",
    "    # ‡∏ï‡∏£‡∏ß‡∏à‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á interval ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô\n",
    "    if now - last_check < CHECK_INTERVAL:\n",
    "        continue\n",
    "    last_check = now\n",
    "    check_dt = datetime.now()\n",
    "    print(f\"\\n--- ‡∏ï‡∏£‡∏ß‡∏à‡∏´‡∏≤ plate ‡πÄ‡∏ß‡∏•‡∏≤: {check_dt.isoformat()} ---\")\n",
    "\n",
    "    # ‡πÉ‡∏ä‡πâ YOLO detect plates (‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ plate ‡∏à‡∏∞‡πÑ‡∏î‡πâ boxes ‡πÄ‡∏õ‡πá‡∏ô empty)\n",
    "    results = model.predict(frame, conf=0.4, verbose=False)\n",
    "    boxes = results[0].boxes.xyxy.cpu().numpy() if len(results) > 0 else []\n",
    "\n",
    "    detected_plate = None\n",
    "    detected_province = None\n",
    "\n",
    "    # ‡∏´‡∏≤‡∏Å‡πÄ‡∏à‡∏≠‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏´‡∏•‡∏≤‡∏¢‡∏Å‡∏•‡πà‡∏≠‡∏á ‡πÉ‡∏´‡πâ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏≠‡πà‡∏≤‡∏ô‡∏ó‡∏∏‡∏Å‡∏Å‡∏•‡πà‡∏≠‡∏á‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡∏ß‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏î‡πâ\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        h_box = y2 - y1\n",
    "        extra = int(h_box * 0.8)  # ‡∏Ç‡∏¢‡∏≤‡∏¢‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏î‡∏¥‡∏° ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Å‡∏¥‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÅ‡∏ô‡πà‡πÜ\n",
    "        y2_expanded = min(frame.shape[0], y2 + extra)\n",
    "        crop = safe_crop(frame, x1, y1, x2, y2_expanded, pad=6)\n",
    "        if crop.size == 0:\n",
    "            continue\n",
    "\n",
    "        # upscale + enhance\n",
    "        crop_up = upscale_image(crop, scale=2)\n",
    "        crop_enh = enhance_for_ocr(crop_up)\n",
    "        cv2.imshow(\"Crop for OCR\", crop_enh)\n",
    "        cv2.waitKey(1)  # 1ms ‡πÅ‡∏Ñ‡πà‡πÉ‡∏´‡πâ‡πÅ‡∏™‡∏î‡∏á ‡πÑ‡∏°‡πà‡∏ö‡∏•‡πá‡∏≠‡∏Å loop\n",
    "\n",
    "        # OCR via EasyOCR_ALPR\n",
    "        ocr_results = ocr_engine.predict(crop_enh)\n",
    "        texts = [r.text.strip() for r in ocr_results if hasattr(r, \"text\") and r.text.strip()]\n",
    "        combined_text = \" \".join(texts)\n",
    "\n",
    "        plate_results = extract_thai_license_plate(combined_text)\n",
    "        if plate_results:\n",
    "            plate_info = plate_results[0]\n",
    "            detected_plate = plate_info.get('plate')\n",
    "            detected_province = plate_info.get('province') or extract_province_from_text(combined_text)\n",
    "            print(f\"  -> ‡∏≠‡πà‡∏≤‡∏ô‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡πÑ‡∏î‡πâ: {detected_plate} {detected_province or ''}\")\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            # ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡∏≠‡∏≤‡∏à‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ combined_text ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏≤ province ‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏≥‡∏≠‡∏∑‡πà‡∏ô (‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà)\n",
    "            continue\n",
    "\n",
    "    # ‡∏Å‡∏£‡∏ì‡∏µ‡πÑ‡∏°‡πà‡∏°‡∏µ plate ‡πÉ‡∏ô‡∏£‡∏≠‡∏ö‡∏ô‡∏µ‡πâ\n",
    "    if detected_plate is None:\n",
    "        print(\"  ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡πâ‡∏≤‡∏¢‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏£‡∏≠‡∏ö‡∏ô‡∏µ‡πâ\")\n",
    "        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏ñ: ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ target ‡πÄ‡∏î‡∏¥‡∏°‡πÑ‡∏õ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏¢ ‡πÜ ‡πÉ‡∏´‡πâ‡πÅ‡∏ï‡πà‡∏•‡∏∞ policy ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏Å‡πá‡∏ö last_seen?\n",
    "        # ‡∏ï‡∏≤‡∏° request: ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏ñ‡∏Å‡πá‡πÑ‡∏°‡πà‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£ (‡πÅ‡∏ï‡πà‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ target expire ‡πÉ‡∏´‡πâ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç)\n",
    "        continue\n",
    "\n",
    "    # ‡∏ñ‡πâ‡∏≤‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ target -> ‡∏ï‡∏±‡πâ‡∏á target ‡πÄ‡∏õ‡πá‡∏ô detected_plate\n",
    "    if target_plate is None:\n",
    "        target_plate = detected_plate\n",
    "        target_first_seen = check_dt\n",
    "        target_last_seen = check_dt\n",
    "        print(f\"  ‡∏ï‡∏±‡πâ‡∏á target ‡πÉ‡∏´‡∏°‡πà: {target_plate} ‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏° {target_first_seen.isoformat()}\")\n",
    "        continue\n",
    "\n",
    "    # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ target ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß -> ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö detected_plate\n",
    "    if detected_plate != target_plate:\n",
    "        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á ‡πÉ‡∏´‡πâ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï target ‡πÄ‡∏õ‡πá‡∏ô detected_plate ‡πÉ‡∏´‡∏°‡πà (‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏Ç‡∏≠)\n",
    "        print(f\"  ‡∏û‡∏ö‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡πÉ‡∏´‡∏°‡πà ({detected_plate}) ‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å target ‡πÄ‡∏î‡∏¥‡∏° ({target_plate}) -> ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï target\")\n",
    "        target_plate = detected_plate\n",
    "        target_first_seen = check_dt\n",
    "        target_last_seen = check_dt\n",
    "        continue\n",
    "    else:\n",
    "        # ‡∏ñ‡πâ‡∏≤‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô (same plate) -> update last_seen ‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡πÄ‡∏ß‡∏•‡∏≤\n",
    "        target_last_seen = check_dt\n",
    "        elapsed = (target_last_seen - target_first_seen).total_seconds()\n",
    "        print(f\"  ‡∏û‡∏ö target ‡πÄ‡∏î‡∏¥‡∏° {target_plate} ‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á (elapsed = {elapsed:.1f} s)\")\n",
    "\n",
    "        if elapsed >= LONG_STAY_THRESHOLD:\n",
    "            # ‡∏ñ‡πâ‡∏≤‡∏ã‡πâ‡∏≥‡πÄ‡∏Å‡∏¥‡∏ô threshold -> ‡πÅ‡∏Ñ‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏±‡πâ‡∏á‡πÄ‡∏ü‡∏£‡∏° (‡∏´‡∏£‡∏∑‡∏≠ crop) + ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å\n",
    "            print(f\"\\n>>> LONG STAY DETECTED: {target_plate}\")\n",
    "            print(f\"    - first_seen: {target_first_seen.isoformat()}\")\n",
    "            print(f\"    - last_seen : {target_last_seen.isoformat()}\")\n",
    "            print(f\"    - elapsed   : {elapsed:.1f} seconds\")\n",
    "            print(f\"    - (‡πÉ‡∏ô‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏à‡∏£‡∏¥‡∏á ‡∏à‡∏∞‡∏™‡πà‡∏á API ‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ö‡∏ú‡∏¥‡∏î‡∏ä‡∏≠‡∏ö‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà)\\n\")\n",
    "            cv2.imwrite(\"frame.png\", frame)\n",
    "            res = upload_image(\"frame.png\")\n",
    "            send_notify(target_plate, \"ad7de137-9287-402a-8b70-53684d96c88f\", res['uploadId'])\n",
    "\n",
    "            # ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡πÅ‡∏Ñ‡∏õ‡πÅ‡∏•‡∏∞‡∏û‡∏¥‡∏°‡∏û‡πå‡πÅ‡∏•‡πâ‡∏ß ‡πÉ‡∏´‡πâ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï target ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏´‡∏≤‡∏£‡∏≠‡∏ö‡πÉ‡∏´‡∏°‡πà\n",
    "            target_plate = None\n",
    "            target_first_seen = None\n",
    "            target_last_seen = None\n",
    "            # ‡πÅ‡∏•‡∏∞ continue loop (‡∏à‡∏∞‡∏£‡∏≠ next CHECK_INTERVAL)\n",
    "            continue\n",
    "\n",
    "# end main loop\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "dl_564",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "livereveal": {
   "height": "100%",
   "margin": 0,
   "maxScale": 1,
   "minScale": 1,
   "scroll": true,
   "start_slideshow_at": "selected",
   "theme": "sky",
   "transition": "zoom",
   "width": "100%"
  },
  "toc": {
   "nav_menu": {
    "height": "369px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "457px",
    "left": "0px",
    "right": "968px",
    "top": "130px",
    "width": "214px"
   },
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
